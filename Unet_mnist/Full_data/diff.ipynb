{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "import random\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "UNET_PATH = 'model_weight/unet.pth'\n",
    "DNN_PATH = 'model_weight/dnn.pth'\n",
    "\n",
    "num_epochs = 24\n",
    "dnn_epoch = 50\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "MNIST = True\n",
    "CIFAR10 = False\n",
    "\n",
    "# Network Training Settings\n",
    "Train_BASE_DNN = True\n",
    "Train_Unet = True\n",
    "\n",
    "if (os.path.exists(DNN_PATH)) == True:\n",
    "    Train_BASE_DNN = False\n",
    "\n",
    "if (os.path.exists(UNET_PATH)) == True:\n",
    "    Train_Unet = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.exists(\"./output\")) == False:\n",
    "    os.mkdir(\"output\")\n",
    "\n",
    "if (os.path.exists(\"./model_weight\")) == False:\n",
    "    os.mkdir(\"model_weight\")\n",
    "\n",
    "if (os.path.exists(\"./test_out\")) == False:\n",
    "    os.mkdir(\"test_out\")\n",
    "\n",
    "for epoch in range (num_epochs):\n",
    "    if (os.path.exists(\"./output/%03d\" % epoch)) == False:\n",
    "        os.mkdir(\"./output/%03d\" % epoch)\n",
    "    else:\n",
    "        files = glob.glob(\"./output/%03d/*.png\" % epoch)\n",
    "\n",
    "        for f in files:\n",
    "          os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST('data', train=True, download=True, \n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.Resize(32),\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "\n",
    "test_dataset =  datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
    "                           transforms.Resize(32),\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyMNISTDataset(Dataset):\n",
    "    def __init__(self, mnist_dataset, noise_schedule, t):\n",
    "        self.mnist_dataset = mnist_dataset\n",
    "        self.noise_schedule = noise_schedule\n",
    "        self.t = t\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.mnist_dataset[index]\n",
    "        noise_level = self.noise_schedule[self.t]\n",
    "        noisy_image = image + torch.randn_like(image) * noise_level\n",
    "        return noisy_image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mnist_dataset)\n",
    "\n",
    "def linear_noise_schedule(T, initial_noise=1.0, final_noise=0.0):\n",
    "    return torch.linspace(initial_noise, final_noise, T)\n",
    "\n",
    "mnist_dataset = MNIST(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "T = 100\n",
    "noise_schedule = linear_noise_schedule(T)\n",
    "\n",
    "noisy_mnist_dataset = NoisyMNISTDataset(mnist_dataset, noise_schedule, t=0) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.activate = nn.ReLU(inplace=True)\n",
    "        self.pool = nn.MaxPool2d((2, 2))\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.sigmod = nn.Sigmoid ()\n",
    "        self.label_embedding = nn.Embedding(10, 512)\n",
    "\n",
    "        self.encoder_1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding= 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding= 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.encoder_2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, padding= 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, padding= 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.encoder_3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, padding= 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding= 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.encoder_4 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3, padding= 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, 3, padding= 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.middle_1_0 = nn.Conv2d(1024, 1024, 3, padding= 1)\n",
    "        self.middle_1_1 = nn.Conv2d(1024, 1024, 3, padding= 1)\n",
    "        \n",
    "       \n",
    "        self.deconv4_0 = nn.ConvTranspose2d(1536, 512, 3, stride=(2,2), padding = 1, output_padding = 1)\n",
    "        self.uconv4_1 = nn.Conv2d(1024, 512, 3, padding= 1) \n",
    "        self.uconv4_2 = nn.Conv2d(512, 512, 3, padding= 1)\n",
    "\n",
    "        self.deconv3_0 = nn.ConvTranspose2d(512, 512, 3, stride=(2,2), padding = 1, output_padding = 1)\n",
    "        self.uconv3_1 = nn.Conv2d(768, 256, 3, padding= 1) \n",
    "        self.uconv3_2 = nn.Conv2d(256, 256, 3, padding= 1)\n",
    "\n",
    "        self.deconv2_0 = nn.ConvTranspose2d(256, 512, 3, stride=(2,2), padding = 1, output_padding = 1)\n",
    "        self.uconv2_1 = nn.Conv2d(640, 128, 3, padding= 1) \n",
    "        self.uconv2_2 = nn.Conv2d(128, 128, 3, padding= 1)\n",
    "\n",
    "        self.deconv1_0 = nn.ConvTranspose2d(128, 512, 3, stride=(2,2), padding = 1, output_padding = 1)\n",
    "        self.uconv1_1 = nn.Conv2d(576, 192, 3, padding= 1) \n",
    "        self.uconv1_2 = nn.Conv2d(192, 192, 3, padding= 1)\n",
    "\n",
    "  \n",
    "        self.out_layer = nn.Conv2d(192, 1, 1)\n",
    "\n",
    "    def forward(self, x, input_labels, target_labels):\n",
    "        conv1 = self.encoder_1(x)\n",
    "        pool1 = self.pool(conv1)\n",
    "        pool1 = self.dropout(pool1)\n",
    "\n",
    "        conv2 = self.encoder_2(pool1)\n",
    "        pool2 = self.pool(conv2)\n",
    "        pool2 = self.dropout(pool2)\n",
    "\n",
    "        conv3 = self.encoder_3(pool2)\n",
    "        pool3 = self.pool(conv3)\n",
    "        pool3 = self.dropout(pool3)\n",
    "\n",
    "        conv4 = self.encoder_4(pool3)\n",
    "        pool4 = self.pool(conv4)\n",
    "        encoder_out = self.dropout(pool4)\n",
    "\n",
    "        input_label_embedding = self.label_embedding(input_labels).view(input_labels.size(0), 512, 1, 1)\n",
    "        x1 = torch.cat([encoder_out, input_label_embedding.expand_as(encoder_out)], dim=1)\n",
    "\n",
    "        convm = self.middle_1_0(x1)\n",
    "        convm = self.activate(convm)\n",
    "        convm = self.middle_1_1(convm)\n",
    "        x2 = self.activate(convm)\n",
    "\n",
    "        target_label_embedding = self.label_embedding(target_labels).view(target_labels.size(0), 512, 1, 1)\n",
    "        x2 = torch.cat([x2, target_label_embedding.expand(x2.size(0), 512, x2.size(2), x2.size(3))], dim=1)\n",
    "\n",
    "        deconv4 = self.deconv4_0(x2)\n",
    "        uconv4 = torch.cat([deconv4, conv4], 1)   # (None, 4, 4, 1024)\n",
    "        uconv4 = self.dropout(uconv4)\n",
    "        uconv4 = self.uconv4_1(uconv4)            # (None, 4, 4, 512)\n",
    "        uconv4 = self.activate(uconv4)\n",
    "        uconv4 = self.uconv4_2(uconv4)            # (None, 4, 4, 512)\n",
    "        uconv4 = self.activate(uconv4)\n",
    "\n",
    "        deconv3 = self.deconv3_0(uconv4)          # (None, 8, 8, 512)\n",
    "        uconv3 = torch.cat([deconv3, conv3], 1)   # (None, 8, 8, 768)\n",
    "        uconv3 = self.dropout(uconv3)\n",
    "        uconv3 = self.uconv3_1(uconv3)            # (None, 8, 8, 256)\n",
    "        uconv3 = self.activate(uconv3)\n",
    "        uconv3 = self.uconv3_2(uconv3)            # (None, 8, 8, 256)\n",
    "        uconv3 = self.activate(uconv3)\n",
    "        \n",
    "        deconv2 = self.deconv2_0(uconv3)          # (None, 16, 16, 512)\n",
    "        uconv2 = torch.cat([deconv2, conv2], 1)   # (None, 16, 16, 640)\n",
    "        uconv2 = self.dropout(uconv2)\n",
    "        uconv2 = self.uconv2_1(uconv2)            # (None, 16, 16, 128)\n",
    "        uconv2 = self.activate(uconv2)\n",
    "        uconv2 = self.uconv2_2(uconv2)            # (None, 16, 16, 128)\n",
    "        uconv2 = self.activate(uconv2)\n",
    "\n",
    "        deconv1 = self.deconv1_0(uconv2)          # (None, 32, 32, 512)\n",
    "        uconv1 = torch.cat([deconv1, conv1], 1)   # (None, 32, 32, 576)\n",
    "        uconv1 = self.dropout(uconv1)\n",
    "        uconv1 = self.uconv1_1(uconv1)            # (None, 32, 32, 192)\n",
    "        uconv1 = self.activate(uconv1)\n",
    "        uconv1 = self.uconv1_2(uconv1)            # (None, 32, 32, 192)\n",
    "        uconv1 = self.activate(uconv1)\n",
    "\n",
    "        out = self.out_layer(uconv1)\n",
    "        out = self.sigmod(out)\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoising_model = UNet(in_channels=1, out_channels=1).cuda()\n",
    "mse_loss = nn.MSELoss()\n",
    "optimizer = optim.Adam(denoising_model.parameters(), lr=1e-3)\n",
    "\n",
    "# Define the noise schedule\n",
    "T = 100\n",
    "noise_schedule = linear_noise_schedule(T)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "    \n",
    "    for t in range(T):\n",
    "        # Create the NoisyMNISTDataset for the current diffusion step t\n",
    "        noisy_mnist_dataset = NoisyMNISTDataset(mnist_dataset, noise_schedule, t)\n",
    "        train_loader = DataLoader(noisy_mnist_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        for i, (noisy_images, labels) in enumerate(train_loader):\n",
    "            noisy_images = noisy_images.cuda()\n",
    "\n",
    "            # Forward pass\n",
    "            denoised_images = denoising_model(noisy_images)\n",
    "\n",
    "            # Compute the denoising score matching loss\n",
    "            noise_level = noise_schedule[t]\n",
    "            noise = (denoised_images - noisy_images) / noise_level\n",
    "            loss = mse_loss(noise, torch.randn_like(noise))\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f'Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_with_label(denoising_model, label, noise_schedule, T, label_embedding):\n",
    "    # Create a random noise image\n",
    "    noise_image = torch.randn(1, 1, 28, 28).cuda()\n",
    "\n",
    "    # Convert the label to a tensor\n",
    "    label_tensor = torch.tensor([label], dtype=torch.long).cuda()\n",
    "\n",
    "    # Perform the reverse diffusion process\n",
    "    for t in reversed(range(T)):\n",
    "        with torch.no_grad():\n",
    "            # Condition the noise_image with the desired label\n",
    "            noise_image_with_label = torch.cat([noise_image, label_embedding(label_tensor).view(1, -1, 1, 1)], dim=1)\n",
    "\n",
    "            # Denoise the image\n",
    "            denoised_image_with_label = denoising_model(noise_image_with_label)\n",
    "\n",
    "            # Compute the noise level and update the noise_image\n",
    "            noise_level = np.sqrt(1 - noise_schedule[t].item())\n",
    "            noise = torch.randn_like(denoised_image_with_label) * noise_level\n",
    "            noise_image = denoised_image_with_label + noise\n",
    "\n",
    "    # Return the generated image\n",
    "    return noise_image.squeeze(0).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_label = 3\n",
    "generated_image = generate_image_with_label(denoising_model, desired_label, noise_schedule, T, denoising_model.label_embedding)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
