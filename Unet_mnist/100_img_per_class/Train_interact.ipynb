{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2eQW6LsWGn9g"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "import numpy as np\n",
        "import random\n",
        "from torchvision.utils import save_image\n",
        "import os\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import glob\n",
        "import cv2\n",
        "import math\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NLcUwp5eGn9h"
      },
      "outputs": [],
      "source": [
        "UNET_PATH = 'model_weight/unet_small.pth'\n",
        "DNN_PATH = 'model_weight/dnn_small.pth'\n",
        "num_epochs = 150\n",
        "dnn_epoch = 200\n",
        "\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 500\n",
        "\n",
        "MNIST = True\n",
        "CIFAR10 = False\n",
        "\n",
        "# Network Training Settings\n",
        "Train_BASE_DNN = True\n",
        "Train_Unet = True\n",
        "\n",
        "if (os.path.exists(DNN_PATH)) == True:\n",
        "    Train_BASE_DNN = False\n",
        "\n",
        "if (os.path.exists(UNET_PATH)) == True:\n",
        "    Train_Unet = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lQwGZoyoGn9h"
      },
      "outputs": [],
      "source": [
        "if (os.path.exists(\"./output\")) == False:\n",
        "    os.mkdir(\"output\")\n",
        "\n",
        "if (os.path.exists(\"./model_weight\")) == False:\n",
        "    os.mkdir(\"model_weight\")\n",
        "\n",
        "if (os.path.exists(\"./test_out\")) == False:\n",
        "    os.mkdir(\"test_out\")\n",
        "\n",
        "for epoch in range (num_epochs):\n",
        "    if (os.path.exists(\"./output/%03d\" % epoch)) == False:\n",
        "        os.mkdir(\"./output/%03d\" % epoch)\n",
        "    else:\n",
        "        files = glob.glob(\"./output/%03d/*.png\" % epoch)\n",
        "\n",
        "        for f in files:\n",
        "          os.remove(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fknwDfwHGn9h"
      },
      "outputs": [],
      "source": [
        "train_dataset = datasets.MNIST('data', train=True, download=True, \n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.Resize(32),\n",
        "                           transforms.ToTensor()\n",
        "                       ]))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
        "\n",
        "test_dataset =  datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
        "                           transforms.Resize(32),\n",
        "                           transforms.ToTensor()\n",
        "                       ]))\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
        "\n",
        "\n",
        "num_samples = int(len(train_dataset) * 0.02)\n",
        "indices = np.random.choice(len(train_dataset), num_samples, replace=False)\n",
        "\n",
        "train_dataset_small = Subset(train_dataset, indices)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset_small, batch_size=BATCH_SIZE, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_vY-uJOGn9h"
      },
      "source": [
        "# VGG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5qbOT3OdGn9i"
      },
      "outputs": [],
      "source": [
        "class VGG11(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGG11, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "irI2VbZ3Gn9i"
      },
      "outputs": [],
      "source": [
        "dnn_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def dnn_test(dnn_model, test_loader):\n",
        "    total = 0\n",
        "    total_correct = 0\n",
        "    test_loss = 0\n",
        "\n",
        "    for i, (images, labels) in enumerate(test_loader):\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        outputs = dnn_model(images)\n",
        "        loss = dnn_criterion(outputs, labels)\n",
        "\n",
        "        _, pred = torch.max(outputs, 1)\n",
        "        correct = pred.eq(labels).cpu().sum().item()\n",
        "        total_correct += correct\n",
        "        total += labels.size(0)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "\n",
        "    return total_correct / total, test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwWy8f1IGn9i",
        "outputId": "5b20c6c4-378c-4ea3-9f94-2a0ad3245d46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training DNN classifier...\n",
            "Epoch 10/200, acc: 0.12 test_acc: 0.1135\n",
            "Epoch 20/200, acc: 0.11666666666666667 test_acc: 0.1135\n",
            "Epoch 30/200, acc: 0.2125 test_acc: 0.1851\n",
            "Epoch 40/200, acc: 0.25083333333333335 test_acc: 0.2727\n",
            "Epoch 50/200, acc: 0.49333333333333335 test_acc: 0.5178\n",
            "Epoch 60/200, acc: 0.625 test_acc: 0.6475\n",
            "Epoch 70/200, acc: 0.6683333333333333 test_acc: 0.6834\n"
          ]
        }
      ],
      "source": [
        "if (Train_BASE_DNN):\n",
        "    dnn_model = VGG11().cuda()\n",
        "    dnn_optimizer = torch.optim.Adam(dnn_model.parameters(), lr=1e-5)\n",
        "\n",
        "    print(\"Training DNN classifier...\")\n",
        "    acc_history = []\n",
        "    test_acc_history = []\n",
        "    for epoch in range(dnn_epoch):\n",
        "        total = 0\n",
        "        total_correct = 0\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = dnn_model(images)\n",
        "            loss = dnn_criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            dnn_optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            dnn_optimizer.step()\n",
        "\n",
        "            _, pred = torch.max(outputs, 1)\n",
        "            correct = pred.eq(labels).cpu().sum().item()\n",
        "            total_correct += correct\n",
        "            total += labels.size(0)\n",
        "\n",
        "        acc_history.append(total_correct / total)\n",
        "        test_acc_history.append(dnn_test(dnn_model, test_loader)[0])\n",
        "    \n",
        "        if((epoch + 1) % 10 == 0):\n",
        "            print(f'Epoch {epoch + 1}/{dnn_epoch}', end = ', ')\n",
        "            print('acc:',acc_history[-1], 'test_acc:', test_acc_history[-1])\n",
        "        \n",
        "    print(\"DNN classifier training complete.\")\n",
        "    torch.save(dnn_model.state_dict(), DNN_PATH)\n",
        "\n",
        "    plt.plot(range(0, dnn_epoch), acc_history)\n",
        "    plt.plot(range(0, dnn_epoch), test_acc_history)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.title(\"Train and test acc on VGG11\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gDu_Ri7Gn9j"
      },
      "outputs": [],
      "source": [
        "dnn_model = VGG11().cuda()\n",
        "dnn_criterion = nn.CrossEntropyLoss()\n",
        "dnn_model.load_state_dict(torch.load(DNN_PATH))\n",
        "\n",
        "print(\"Testing DNN classifier...\")\n",
        "\n",
        "test_acc, test_loss = dnn_test(dnn_model, test_loader)\n",
        "\n",
        "print(\"Test Acc:\" , test_acc)\n",
        "print(\"DNN classifier Test complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwJegXCdGn9j"
      },
      "source": [
        "# Unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMNFUIGDGn9j"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "        self.activate = nn.ReLU(inplace=True)\n",
        "        self.pool = nn.MaxPool2d((2, 2))\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.sigmod = nn.Sigmoid ()\n",
        "        self.label_embedding = nn.Embedding(10, 512)\n",
        "\n",
        "        self.encoder_1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 3, padding= 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, 3, padding= 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        self.encoder_2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3, padding= 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, 3, padding= 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        self.encoder_3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, 3, padding= 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding= 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        self.encoder_4 = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, 3, padding= 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, 3, padding= 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        \n",
        "        self.middle_1_0 = nn.Conv2d(1024, 1024, 3, padding= 1)\n",
        "        self.middle_1_1 = nn.Conv2d(1024, 1024, 3, padding= 1)\n",
        "        \n",
        "       \n",
        "        self.deconv4_0 = nn.ConvTranspose2d(1536, 512, 3, stride=(2,2), padding = 1, output_padding = 1)\n",
        "        self.uconv4_1 = nn.Conv2d(1024, 512, 3, padding= 1) \n",
        "        self.uconv4_2 = nn.Conv2d(512, 512, 3, padding= 1)\n",
        "\n",
        "        self.deconv3_0 = nn.ConvTranspose2d(512, 512, 3, stride=(2,2), padding = 1, output_padding = 1)\n",
        "        self.uconv3_1 = nn.Conv2d(768, 256, 3, padding= 1) \n",
        "        self.uconv3_2 = nn.Conv2d(256, 256, 3, padding= 1)\n",
        "\n",
        "        self.deconv2_0 = nn.ConvTranspose2d(256, 512, 3, stride=(2,2), padding = 1, output_padding = 1)\n",
        "        self.uconv2_1 = nn.Conv2d(640, 128, 3, padding= 1) \n",
        "        self.uconv2_2 = nn.Conv2d(128, 128, 3, padding= 1)\n",
        "\n",
        "        self.deconv1_0 = nn.ConvTranspose2d(128, 512, 3, stride=(2,2), padding = 1, output_padding = 1)\n",
        "        self.uconv1_1 = nn.Conv2d(576, 192, 3, padding= 1) \n",
        "        self.uconv1_2 = nn.Conv2d(192, 192, 3, padding= 1)\n",
        "\n",
        "  \n",
        "        self.out_layer = nn.Conv2d(192, 1, 1)\n",
        "\n",
        " \n",
        "\n",
        "    def forward(self, x, input_labels, target_labels):\n",
        "        conv1 = self.encoder_1(x)\n",
        "        pool1 = self.pool(conv1)\n",
        "        pool1 = self.dropout(pool1)\n",
        "\n",
        "        conv2 = self.encoder_2(pool1)\n",
        "        pool2 = self.pool(conv2)\n",
        "        pool2 = self.dropout(pool2)\n",
        "\n",
        "        conv3 = self.encoder_3(pool2)\n",
        "        pool3 = self.pool(conv3)\n",
        "        pool3 = self.dropout(pool3)\n",
        "\n",
        "        conv4 = self.encoder_4(pool3)\n",
        "        pool4 = self.pool(conv4)\n",
        "        encoder_out = self.dropout(pool4)\n",
        "\n",
        "        input_label_embedding = self.label_embedding(input_labels).view(input_labels.size(0), 512, 1, 1)\n",
        "        x1 = torch.cat([encoder_out, input_label_embedding.expand_as(encoder_out)], dim=1)\n",
        "\n",
        "        convm = self.middle_1_0(x1)\n",
        "        convm = self.activate(convm)\n",
        "        convm = self.middle_1_1(convm)\n",
        "        x2 = self.activate(convm)\n",
        "\n",
        "        target_label_embedding = self.label_embedding(target_labels).view(target_labels.size(0), 512, 1, 1)\n",
        "        x2 = torch.cat([x2, target_label_embedding.expand(x2.size(0), 512, x2.size(2), x2.size(3))], dim=1)\n",
        "\n",
        "        deconv4 = self.deconv4_0(x2)\n",
        "        uconv4 = torch.cat([deconv4, conv4], 1)   # (None, 4, 4, 1024)\n",
        "        uconv4 = self.dropout(uconv4)\n",
        "        uconv4 = self.uconv4_1(uconv4)            # (None, 4, 4, 512)\n",
        "        uconv4 = self.activate(uconv4)\n",
        "        uconv4 = self.uconv4_2(uconv4)            # (None, 4, 4, 512)\n",
        "        uconv4 = self.activate(uconv4)\n",
        "\n",
        "        deconv3 = self.deconv3_0(uconv4)          # (None, 8, 8, 512)\n",
        "        uconv3 = torch.cat([deconv3, conv3], 1)   # (None, 8, 8, 768)\n",
        "        uconv3 = self.dropout(uconv3)\n",
        "        uconv3 = self.uconv3_1(uconv3)            # (None, 8, 8, 256)\n",
        "        uconv3 = self.activate(uconv3)\n",
        "        uconv3 = self.uconv3_2(uconv3)            # (None, 8, 8, 256)\n",
        "        uconv3 = self.activate(uconv3)\n",
        "        \n",
        "        deconv2 = self.deconv2_0(uconv3)          # (None, 16, 16, 512)\n",
        "        uconv2 = torch.cat([deconv2, conv2], 1)   # (None, 16, 16, 640)\n",
        "        uconv2 = self.dropout(uconv2)\n",
        "        uconv2 = self.uconv2_1(uconv2)            # (None, 16, 16, 128)\n",
        "        uconv2 = self.activate(uconv2)\n",
        "        uconv2 = self.uconv2_2(uconv2)            # (None, 16, 16, 128)\n",
        "        uconv2 = self.activate(uconv2)\n",
        "\n",
        "        deconv1 = self.deconv1_0(uconv2)          # (None, 32, 32, 512)\n",
        "        uconv1 = torch.cat([deconv1, conv1], 1)   # (None, 32, 32, 576)\n",
        "        uconv1 = self.dropout(uconv1)\n",
        "        uconv1 = self.uconv1_1(uconv1)            # (None, 32, 32, 192)\n",
        "        uconv1 = self.activate(uconv1)\n",
        "        uconv1 = self.uconv1_2(uconv1)            # (None, 32, 32, 192)\n",
        "        uconv1 = self.activate(uconv1)\n",
        "\n",
        "        out = self.out_layer(uconv1)\n",
        "        out = self.sigmod(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSn-tPDfGn9j"
      },
      "outputs": [],
      "source": [
        "def perceptual_loss(vgg_model, input_images, output_images):\n",
        "    feature_layers = [vgg_model.features[i] for i in range(len(vgg_model.features))]\n",
        "    feature_extractor = nn.Sequential(*feature_layers[:-1]).cuda()\n",
        "    \n",
        "    input_features = feature_extractor(input_images)\n",
        "    output_features = feature_extractor(output_images)\n",
        "    \n",
        "    return nn.functional.mse_loss(input_features, output_features)\n",
        "\n",
        "def total_variation_regularization(images):\n",
        "    tv_h = torch.sum(torch.abs(images[:, :, 1:, :] - images[:, :, :-1, :]))\n",
        "    tv_w = torch.sum(torch.abs(images[:, :, :, 1:] - images[:, :, :, :-1]))\n",
        "    return tv_h + tv_w\n",
        "\n",
        "def generate_synthetic_digits(digit, count):\n",
        "    all_digit_indices = np.where(train_dataset_small.dataset.targets.cpu() == digit.cpu())[0]\n",
        "    digit_indices = np.intersect1d(all_digit_indices, indices)\n",
        "    \n",
        "    if len(digit_indices) == 0:\n",
        "        raise ValueError(f\"No samples found for label {digit.item()}\")\n",
        "        \n",
        "    selected_indices = np.random.choice(digit_indices, count, replace=True)\n",
        "    synthetic_digits = torch.stack([train_dataset[i][0] for i in selected_indices])\n",
        "    return synthetic_digits\n",
        "\n",
        "# Erode the input images to remove the digit information\n",
        "def erode_images(images):\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
        "    eroded_images = []\n",
        "    for image in images:\n",
        "        gray_image = image.squeeze(0).detach().cpu().numpy()\n",
        "        eroded_image = cv2.erode(gray_image, kernel, iterations=1)\n",
        "        eroded_images.append(eroded_image)\n",
        "    \n",
        "    eroded_images_np = np.array(eroded_images)\n",
        "    return torch.tensor(eroded_images_np).unsqueeze(1).cuda()\n",
        "\n",
        "vgg = models.vgg16(pretrained=True).features.eval().cuda()\n",
        "\n",
        "# Function to extract features for a batch of images using the VGG model\n",
        "def extract_features(images):\n",
        "    with torch.no_grad():\n",
        "        features = vgg(images)\n",
        "    return features.view(images.size(0), -1)\n",
        "\n",
        "def find_nearest_neighbor(images, target_labels, target_label, eroded_images, synthetic_target_digits):\n",
        "    target_images = eroded_images * 0.1 + synthetic_target_digits * 0.9\n",
        "    target_images = target_images[target_labels == target_label]\n",
        "    \n",
        "    # Convert the MNIST images to 3-channel format for VGG model\n",
        "    images_3channel = images.repeat(1, 3, 1, 1)\n",
        "    target_images_3channel = target_images.repeat(1, 3, 1, 1)\n",
        "    \n",
        "    # Extract features for input images and target_images\n",
        "    input_features = extract_features(images_3channel)\n",
        "    target_features = extract_features(target_images_3channel)\n",
        "\n",
        "    # Compute distances between input_features and target_features\n",
        "    input_features_expanded = input_features.unsqueeze(1)\n",
        "    target_features_expanded = target_features.unsqueeze(0)\n",
        "\n",
        "    # Compute distances between input images and target_images\n",
        "    distances = (input_features_expanded - target_features_expanded).view(images.size(0), target_images.size(0), -1).norm(dim=2)\n",
        "\n",
        "    # Find the index of the input image with the smallest distance to the selected target_image\n",
        "    min_distances, min_indices = distances.min(dim=1)\n",
        "    closest_input_image_index = min_indices[min_distances.argmin()]\n",
        "    \n",
        "    return target_images[distances.argmin()]\n",
        "\n",
        "def compare_histograms(images1, images2, images3, epoch, i):\n",
        "    images1_flat = images1.reshape(-1)\n",
        "    images2_flat = images2.reshape(-1)\n",
        "    images3_flat = images3.reshape(-1)\n",
        "    \n",
        "    plt.figure()\n",
        "    plt.hist(images1_flat, bins=10, alpha=0.5, label='Original Images')\n",
        "    plt.hist(images2_flat, bins=10, alpha=0.5, label='Target Images')\n",
        "    plt.hist(images3_flat, bins=10, alpha=0.5, label='Reconstructed Images')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.savefig(\"./output/%03d/%04d_dist.png\" % ( epoch, i))\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnphmpuKGn9j"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "if (Train_Unet):\n",
        "    # Initialize model, loss, and optimizer\n",
        "    model = UNet().cuda()\n",
        "    dnn_model = VGG11().cuda()\n",
        "    dnn_model.load_state_dict(torch.load(DNN_PATH))\n",
        "    dnn_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Freeze the DNN classifier weights\n",
        "    for param in dnn_model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Hyperparameters\n",
        "    alpha = 0.5\n",
        "    beta = 0.5\n",
        "\n",
        "    learning_rate = 1e-5\n",
        "    step_size = 20\n",
        "    gamma = 0.7\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    # scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "    loss_history = []\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "        epoch_loss = 0\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "            target_labels = (labels + torch.randint(1, 9, size=(labels.size(0),)).cuda()) % 10\n",
        "\n",
        "            outputs = model(images, labels, target_labels)\n",
        "            \n",
        "            # Generate target images (same digit as target labels)\n",
        "            eroded_images = erode_images(images)\n",
        "            synthetic_target_digits = torch.cat([generate_synthetic_digits(d, 1) for d in target_labels]).cuda()\n",
        "            # Generate target images (same digit as target labels)\n",
        "            target_images = images.clone()\n",
        "            for j in range(labels.size(0)):\n",
        "               target_images[j] = find_nearest_neighbor(images, target_labels, target_labels[j], eroded_images, synthetic_target_digits)\n",
        "\n",
        "            # Compute reconstruction loss\n",
        "            reconstruction_loss = criterion(outputs, target_images)\n",
        "\n",
        "            # Train the classifier on the reconstructed images\n",
        "            classifier_outputs = dnn_model(outputs)\n",
        "            classification_loss = dnn_criterion(classifier_outputs, target_labels)\n",
        "            loss_on_loss = torch.abs(test_loss - classification_loss)\n",
        "            p_loss = perceptual_loss(dnn_model, images, outputs)\n",
        "\n",
        "            # Total loss\n",
        "            total_loss = 10 * reconstruction_loss + alpha * classification_loss + beta * p_loss + loss_on_loss\n",
        "            epoch_loss += total_loss.item()\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i+1) % 2 == 0:\n",
        "                print('Step [', i + 1, '/', len(train_loader),']'\n",
        "                    'loss:' , total_loss.data.cpu().numpy(), \n",
        "                      'recon loss:', 10 * reconstruction_loss.data.cpu().numpy(), \n",
        "                      'dnn loss:', alpha * classification_loss.data.cpu().numpy(),\n",
        "                      'loss on loss:', loss_on_loss.data.cpu().numpy(),\n",
        "                      'p_loss:', beta * p_loss.data.cpu().numpy())\n",
        "                \n",
        "                save_image(outputs.data, './output/%03d/%04d_recon.png' % ( epoch, i))\n",
        "                save_image(images.data, './output/%03d/%04d_img.png' % ( epoch, i))\n",
        "                save_image(target_images.data, './output/%03d/%04d_target.png' % ( epoch, i))\n",
        "\n",
        "                # Convert the images to NumPy arrays\n",
        "                images_np = images.cpu().numpy()\n",
        "                target_images_np = target_images.cpu().numpy()\n",
        "                reconstructed_images_np = outputs.detach().cpu().numpy()\n",
        "\n",
        "                compare_histograms(images_np, target_images_np, reconstructed_images_np, epoch, i)\n",
        "\n",
        "        loss_history.append(epoch_loss)\n",
        "\n",
        "\n",
        "    torch.save(model.state_dict(), UNET_PATH)\n",
        "    plt.plot(range(0, num_epochs), loss_history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzMw4RfhGn9k"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JEYneuBGn9k"
      },
      "outputs": [],
      "source": [
        "def generate_augmented_test_images(model, test_loader, num_augmented_images=1000):\n",
        "    augmented_images = []\n",
        "    augmented_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "            target_labels = (labels + torch.randint(1, 9, size=(labels.size(0),)).cuda()) % 10\n",
        "            outputs = model(images, labels, target_labels)\n",
        "            \n",
        "            augmented_images.append(outputs.cpu())\n",
        "            augmented_labels.append(target_labels.cpu())\n",
        "            \n",
        "            if len(augmented_images) * labels.size(0) >= num_augmented_images:\n",
        "                break\n",
        "    \n",
        "    augmented_images = torch.cat(augmented_images)[:num_augmented_images]\n",
        "    augmented_labels = torch.cat(augmented_labels)[:num_augmented_images]\n",
        "    \n",
        "    return augmented_images, augmented_labels\n",
        "\n",
        "augmented_test_images, augmented_test_labels = generate_augmented_test_images(model, test_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-neAjXJqGn9k"
      },
      "outputs": [],
      "source": [
        "resized_train_images = torch.stack([train_dataset_small.dataset[i][0] for i in indices])\n",
        "    \n",
        "train_images = torch.cat([resized_train_images, augmented_test_images])\n",
        "train_labels = torch.cat([torch.tensor(train_dataset_small.dataset.targets )[indices], augmented_test_labels])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vs9U8uFZGn9k"
      },
      "outputs": [],
      "source": [
        "train_dataset_extended = TensorDataset(train_images, train_labels)\n",
        "train_loader_extended = DataLoader(train_dataset_extended, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5_B-WE7Gn9k"
      },
      "outputs": [],
      "source": [
        "dnn_model = VGG11().cuda()  # Define your classifier (e.g., a CNN)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(dnn_model.parameters(), lr=1e-5)\n",
        "\n",
        "# Training loop for the new classifier\n",
        "acc_history = []\n",
        "test_acc_history = []\n",
        "for epoch in range(dnn_epoch):\n",
        "    total_correct = 0\n",
        "    total = 0\n",
        "    for i, (images, labels) in enumerate(train_loader_extended):\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = dnn_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, pred = torch.max(outputs, 1)\n",
        "        correct = pred.eq(labels).cpu().sum().item()\n",
        "        total_correct += correct\n",
        "        total += labels.size(0)\n",
        "\n",
        "    if((epoch + 1 )% 10 == 0):\n",
        "        print(f'Epoch {epoch + 1}/{dnn_epoch}', end = ', ')\n",
        "        print('acc:',acc_history[-1], 'test_acc:', test_acc_history[-1])\n",
        "    acc_history.append(total_correct / total)\n",
        "    test_acc_history.append(dnn_test(dnn_model, test_loader)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObwI8aRTGn9k"
      },
      "outputs": [],
      "source": [
        "plt.plot(range(0, dnn_epoch), acc_history)\n",
        "plt.plot(range(0, dnn_epoch), test_acc_history)\n",
        "plt.ylim(0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPg4EG6PGn9k"
      },
      "source": [
        "# Unet Recon Img "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HOjVwr6Gn9k"
      },
      "outputs": [],
      "source": [
        "image = plt.imread('./output/%03d/0009_img.png'% (num_epochs -1))\n",
        "plt.figure(figsize = (10,10))\n",
        "plt.imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-xkZxocGn9k"
      },
      "outputs": [],
      "source": [
        "image = plt.imread('./output/%03d/0009_recon.png'% (num_epochs -1))\n",
        "plt.figure(figsize = (10,10))\n",
        "plt.imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = plt.imread('./output/%03d/0009_target.png'% (num_epochs -1))\n",
        "plt.figure(figsize = (10,10))\n",
        "plt.imshow(image)"
      ],
      "metadata": {
        "id": "MTCN8xO0HXt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZnZeX7iGn9k"
      },
      "outputs": [],
      "source": [
        "image = plt.imread('./output/%03d/0009_dist.png'% (num_epochs -1))\n",
        "plt.figure(figsize = (8,8))\n",
        "plt.imshow(image)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}