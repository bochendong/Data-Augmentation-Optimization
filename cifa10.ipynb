{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRMTWSlXhz1lJOIz1x9C2j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bochendong/giao_bochen/blob/main/cifa10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ee58nKM9tSpJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import random\n",
        "from torchvision.utils import save_image\n",
        "import os\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Prepare"
      ],
      "metadata": {
        "id": "BpdsolAZtynW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if (os.path.exists(\"./output\")) == False:\n",
        "    os.mkdir(\"output\")\n",
        "\n",
        "if (os.path.exists(\"./model_weight\")) == False:\n",
        "    os.mkdir(\"model_weight\")\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 30\n",
        "\n",
        "for epoch in range (EPOCHS):\n",
        "    if (os.path.exists(\"./output/%03d\" % epoch)) == False:\n",
        "        os.mkdir(\"./output/%03d\" % epoch)\n",
        "    else:\n",
        "        files = glob.glob(\"./output/%03d/*.png\" % epoch)\n",
        "\n",
        "        for f in files:\n",
        "          os.remove(f)"
      ],
      "metadata": {
        "id": "9cZyGvc4tUNt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "vJ9LTVHQtVrc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=1)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRk-EOEStXEF",
        "outputId": "b598c89d-218c-4cdf-dfaa-d5730fb83c45"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_iter = iter(trainloader)\n",
        "test_img, test_label = next(dataset_iter)"
      ],
      "metadata": {
        "id": "7IDif9wEvd1H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToxjirKdv5Vy",
        "outputId": "fb627821-4995-4ec5-d891-13a6d1113225"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_label.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlK6kry6v6d8",
        "outputId": "30bfd633-5f38-44c2-e547-a3610a6f74f2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unet"
      ],
      "metadata": {
        "id": "MDAUsl5ttdj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size = 3)\n",
        "        self.relu  = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size = 3)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.relu(self.conv2(self.relu(self.conv1(x))))\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, chs = (3, 64, 128)):\n",
        "        super().__init__()\n",
        "        self.enc_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)])\n",
        "        self.pool       = nn.MaxPool2d(2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        ftrs = []\n",
        "        for block in self.enc_blocks:\n",
        "            x = block(x)\n",
        "            ftrs.append(x)\n",
        "            x = self.pool(x)\n",
        "        return ftrs\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, chs = (128, 64)):\n",
        "        super().__init__()\n",
        "        self.chs         = chs\n",
        "        self.upconvs    = nn.ModuleList([nn.ConvTranspose2d(chs[i], chs[i+1], 2, 2) for i in range(len(chs)-1)])\n",
        "        self.dec_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)]) \n",
        "        \n",
        "    def forward(self, x, encoder_features):\n",
        "        for i in range(len(self.chs)-1):\n",
        "            x        = self.upconvs[i](x)\n",
        "            enc_ftrs = self.crop(encoder_features[i], x)\n",
        "            x        = torch.cat([x, enc_ftrs], dim=1)\n",
        "            x        = self.dec_blocks[i](x)\n",
        "        return x\n",
        "    \n",
        "    def crop(self, enc_ftrs, x):\n",
        "        _, _, H, W = x.shape\n",
        "        enc_ftrs   = torchvision.transforms.CenterCrop([H, W])(enc_ftrs)\n",
        "        return enc_ftrs\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, enc_chs = (3, 64, 128), dec_chs = (128, 64), \n",
        "                    num_class = 3, retain_dim = True, out_sz = (32, 32)):\n",
        "        super().__init__()\n",
        "        self.encoder     = Encoder(enc_chs)\n",
        "        self.decoder     = Decoder(dec_chs)\n",
        "        self.head        = nn.Conv2d(dec_chs[-1], num_class, 1)\n",
        "\n",
        "        self.retain_dim  = retain_dim\n",
        "        self.out_sz      = out_sz\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc_ftrs = self.encoder(x)\n",
        "        out      = self.decoder(enc_ftrs[::-1][0], enc_ftrs[::-1][1:])\n",
        "        out      = self.head(out)\n",
        "        if self.retain_dim:\n",
        "            out = F.interpolate(out, self.out_sz)\n",
        "        return out\n",
        "     "
      ],
      "metadata": {
        "id": "frT_ZkVmtY61"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_training(model, train_loader, loss_fn, optimizer, epoch, use_cuda = True):\n",
        "    dataset_iter = iter(train_loader)\n",
        "    len_dataloader = len(dataset_iter)\n",
        "\n",
        "    i = 0\n",
        "    loss_sum = 0\n",
        "    while i < len_dataloader:\n",
        "        img, true_label = next(dataset_iter)\n",
        "        optimizer.zero_grad()\n",
        "        if use_cuda:\n",
        "            img, true_label = img.cuda(), true_label.cuda()\n",
        "\n",
        "        recon = model(img)\n",
        "        loss = loss_fn(recon, img)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_sum += loss\n",
        "\n",
        "        if  i % 100 == 0:\n",
        "            real = img.data\n",
        "            reconstruction= recon.data\n",
        "\n",
        "            save_image(real, './output/%03d/%d_A.png' % ( epoch, i))\n",
        "            save_image(reconstruction, 'output/%03d/%d_reconA.png' % ( epoch, i))\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    print(\"e:\", epoch, loss_sum)\n"
      ],
      "metadata": {
        "id": "Q8-1aPa_wYe8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet = UNet()\n",
        "\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(unet.parameters(), lr=learning_rate)\n",
        "recon_loss_fn = nn.L1Loss()\n",
        "\n",
        "if (torch.cuda.is_available()):\n",
        "    recon_loss_fn = recon_loss_fn.cuda()\n",
        "    unet.cuda()"
      ],
      "metadata": {
        "id": "U6RmGup_wyzE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for e in range(30):\n",
        "    unet_training(model=unet, train_loader = trainloader, \n",
        "                 loss_fn = recon_loss_fn, optimizer = optimizer, \n",
        "                 epoch = e, use_cuda = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V6gRqxrxFnS",
        "outputId": "0dbf4963-0377-4e35-bd6b-da75e6d54af0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e: 0 tensor(117.8972, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 1 tensor(107.4478, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 2 tensor(104.7686, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 3 tensor(102.9117, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 4 tensor(101.5591, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 5 tensor(100.5021, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 6 tensor(99.5055, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 7 tensor(98.8449, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 8 tensor(98.2580, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 9 tensor(97.7451, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 10 tensor(97.2287, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 11 tensor(96.7663, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 12 tensor(96.3375, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 13 tensor(95.8918, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 14 tensor(95.5500, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 15 tensor(95.1934, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 16 tensor(94.8509, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 17 tensor(94.4587, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 18 tensor(94.2026, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 19 tensor(93.9174, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 20 tensor(93.7101, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 21 tensor(93.4294, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 22 tensor(93.2195, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 23 tensor(92.9431, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 24 tensor(92.7090, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 25 tensor(92.5705, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 26 tensor(92.3275, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 27 tensor(92.1306, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 28 tensor(91.9840, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "e: 29 tensor(91.7865, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DNN"
      ],
      "metadata": {
        "id": "S6EW9VQe4-Sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "FKbLd1LJ4dbN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dnn_training(dnn, train_loader, criterion, optimizer, epoch, use_cuda):\n",
        "    dataset_iter = iter(train_loader)\n",
        "    len_dataloader = len(dataset_iter)\n",
        "\n",
        "    i = 0\n",
        "    loss_sum = 0\n",
        "    total = 0\n",
        "    correct_label = 0\n",
        "\n",
        "    while i < len_dataloader:\n",
        "        total += BATCH_SIZE\n",
        "        img, true_label = next(dataset_iter)\n",
        "        optimizer.zero_grad()\n",
        "        if use_cuda:\n",
        "            img, true_label = img.cuda(), true_label.cuda()\n",
        "\n",
        "        y_pred_on_recon = dnn(img)\n",
        "        loss = criterion(y_pred_on_recon, true_label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_sum += loss\n",
        "\n",
        "        _, predicted = torch.max(y_pred_on_recon.data, 1)\n",
        "        correct_label += predicted.eq(true_label.data).cpu().sum().item()\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    print(\"e:\", epoch, loss_sum, 'acc: ', correct_label/total)\n",
        "\n",
        "def dnn_testing(dnn, test_loader, criterion, use_cuda):\n",
        "    dataset_iter = iter(test_loader)\n",
        "    len_dataloader = len(dataset_iter)\n",
        "\n",
        "    i = 0\n",
        "    loss_sum = 0\n",
        "    total = 0\n",
        "    correct_label = 0\n",
        "\n",
        "    while i < len_dataloader:\n",
        "        total += BATCH_SIZE\n",
        "        img, true_label = next(dataset_iter)\n",
        "\n",
        "        if use_cuda:\n",
        "            img, true_label = img.cuda(), true_label.cuda()\n",
        "\n",
        "        y_pred = dnn(img)\n",
        "        loss = criterion(y_pred, true_label)\n",
        "\n",
        "        optimizer.step()\n",
        "        loss_sum += loss\n",
        "\n",
        "        _, predicted = torch.max(y_pred.data, 1)\n",
        "        correct_label += predicted.eq(true_label.data).cpu().sum().item()\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    print(\"testing:\", loss_sum, 'acc: ', correct_label/total)"
      ],
      "metadata": {
        "id": "HMTcWnDw4q9i"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline = DNN()\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(baseline.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "if (torch.cuda.is_available()):\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "    loss_fn = loss_fn.cuda()\n",
        "    baseline.cuda()"
      ],
      "metadata": {
        "id": "QnuUDvFP4hGO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for e in range(EPOCHS):\n",
        "    dnn_training(dnn = baseline,\n",
        "                 train_loader = trainloader, \n",
        "                 criterion = loss_fn, \n",
        "                 optimizer = optimizer, \n",
        "                 epoch = e,\n",
        "                 use_cuda = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJ2MkU3I4n2i",
        "outputId": "1a1e40c4-4efd-40f7-c7da-81eb5380e1a1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e: 0 tensor(804.1334, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.23549392583120204\n",
            "e: 1 tensor(691.6365, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.3559582800511509\n",
            "e: 2 tensor(650.0811, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.390684942455243\n",
            "e: 3 tensor(627.7081, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.41374280690537085\n",
            "e: 4 tensor(612.3911, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.43054667519181583\n",
            "e: 5 tensor(600.9468, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.44259510869565216\n",
            "e: 6 tensor(591.3448, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.45408407928388744\n",
            "e: 7 tensor(582.6982, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.4631553708439898\n",
            "e: 8 tensor(575.2344, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.4687699808184143\n",
            "e: 9 tensor(568.4309, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.47570332480818417\n",
            "e: 10 tensor(561.6481, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.48127797314578\n",
            "e: 11 tensor(555.7025, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.4865529092071611\n",
            "e: 12 tensor(550.3357, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.4920276534526854\n",
            "e: 13 tensor(544.6722, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.4973025895140665\n",
            "e: 14 tensor(539.4661, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.5030770460358056\n",
            "e: 15 tensor(534.9413, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.5055147058823529\n",
            "e: 16 tensor(529.5891, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.5122282608695652\n",
            "e: 17 tensor(525.3650, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.5161045396419437\n",
            "e: 18 tensor(521.8252, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.5194013746803069\n",
            "e: 19 tensor(516.9095, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.5248761189258312\n",
            "e: 20 tensor(513.1970, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.5277533567774936\n",
            "e: 21 tensor(509.5444, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.5327685421994884\n",
            "e: 22 tensor(504.8182, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.5360453964194374\n",
            "e: 23 tensor(501.4760, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.537703804347826\n",
            "e: 24 tensor(497.9463, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.5429587595907929\n",
            "e: 25 tensor(494.4165, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.5458559782608695\n",
            "e: 26 tensor(490.7569, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.5490728900255755\n",
            "e: 27 tensor(488.1730, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.5521499360613811\n",
            "e: 28 tensor(485.3952, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.5557464833759591\n",
            "e: 29 tensor(481.5393, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.559462915601023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dnn_testing(dnn = baseline, test_loader = testloader, criterion = loss_fn, use_cuda=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycEPmQke42sK",
        "outputId": "7299a0c6-822d-4c17-ff2c-e0fce86d7f3c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "testing: tensor(755.0688, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.21054193037974683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pred on reconstruct"
      ],
      "metadata": {
        "id": "f0bgtgVWIpp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training(dnn, unet, train_loader, loss_fn, recon_loss_fn, optimizer_dnn, optimizer_unet, epoch, use_cuda):\n",
        "    dataset_iter = iter(train_loader)\n",
        "    len_dataloader = len(dataset_iter)\n",
        "\n",
        "    i = 0\n",
        "    loss_sum = 0\n",
        "    total = 0\n",
        "    correct_label = 0\n",
        "\n",
        "    while i < len_dataloader:\n",
        "        total += BATCH_SIZE\n",
        "        img, true_label = next(dataset_iter)\n",
        "        optimizer_dnn.zero_grad()\n",
        "        optimizer_unet.zero_grad()\n",
        "        if use_cuda:\n",
        "            img, true_label = img.cuda(), true_label.cuda()\n",
        "\n",
        "        recon = unet(img)\n",
        "        y_pred_on_recon = dnn(recon)\n",
        "\n",
        "        loss = loss_fn(y_pred_on_recon, true_label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer_dnn.step()\n",
        "        optimizer_unet.step()\n",
        "        loss_sum += loss\n",
        "\n",
        "        _, predicted = torch.max(y_pred_on_recon.data, 1)\n",
        "        correct_label += predicted.eq(true_label.data).cpu().sum().item()\n",
        "\n",
        "        if  i % 100 == 0:\n",
        "            real = img.data\n",
        "            reconstruction= recon.data\n",
        "\n",
        "            save_image(real, './output/%03d/%d_A.png' % ( epoch, i))\n",
        "            save_image(reconstruction, 'output/%03d/%d_reconA.png' % ( epoch, i))\n",
        "\n",
        "        i += 1\n",
        "    print(\"e:\", epoch, loss_sum, 'acc: ', correct_label/total)\n",
        "\n",
        "def testing(dnn, unet, criterion, test_loader, use_cuda):\n",
        "    dataset_iter = iter(test_loader)\n",
        "    len_dataloader = len(dataset_iter)\n",
        "\n",
        "    i = 0\n",
        "    loss_sum = 0\n",
        "    total = 0\n",
        "    correct_label = 0\n",
        "\n",
        "    while i < len_dataloader:\n",
        "        total += BATCH_SIZE\n",
        "        img, true_label = next(dataset_iter)\n",
        "\n",
        "        if use_cuda:\n",
        "            img, true_label = img.cuda(), true_label.cuda()\n",
        "\n",
        "        recon = unet(img)\n",
        "        y_pred_on_recon = dnn(recon)\n",
        "\n",
        "        loss = criterion(y_pred_on_recon, true_label)\n",
        "        loss_sum += loss\n",
        "\n",
        "        _, predicted = torch.max(y_pred_on_recon.data, 1)\n",
        "        correct_label += predicted.eq(true_label.data).cpu().sum().item()\n",
        "\n",
        "        i += 1\n",
        "    print(\"Testing:\", loss_sum, 'acc: ', correct_label/total)"
      ],
      "metadata": {
        "id": "SlhTVPKLIpLF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dnn = DNN()\n",
        "unet = UNet()\n",
        "\n",
        "learning_rate = 1e-4\n",
        "\n",
        "optimizer_dnn = torch.optim.Adam(dnn.parameters(), lr=learning_rate)\n",
        "optimizer_unet = torch.optim.Adam(unet.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "recon_loss_fn = nn.MSELoss()"
      ],
      "metadata": {
        "id": "DFf_Na9KIwc9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if (torch.cuda.is_available()):\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "    loss_fn = loss_fn.cuda()\n",
        "    recon_loss_fn = recon_loss_fn.cuda()\n",
        "    dnn.cuda()\n",
        "    unet.cuda()"
      ],
      "metadata": {
        "id": "9D9DpBtCI3eV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for e in range(EPOCHS):\n",
        "    training(dnn = dnn,\n",
        "                 unet=unet,\n",
        "                 train_loader = trainloader, \n",
        "                 loss_fn = loss_fn, \n",
        "                 recon_loss_fn = recon_loss_fn,\n",
        "                 optimizer_dnn = optimizer_dnn, \n",
        "                 optimizer_unet = optimizer_unet,\n",
        "                 epoch = e,\n",
        "                 use_cuda = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD7Iqd-II4Ie",
        "outputId": "b0b0dceb-71f7-4d91-f3ea-d10984ba0102"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e: 0 tensor(789.8221, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.22912004475703324\n",
            "e: 1 tensor(702.7535, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.3131993286445013\n",
            "e: 2 tensor(669.8340, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.36111333120204603\n",
            "e: 3 tensor(636.6530, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.3992167519181586\n",
            "e: 4 tensor(612.8073, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.42443254475703324\n",
            "e: 5 tensor(592.0802, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.44651134910485935\n",
            "e: 6 tensor(573.3353, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.46457400895140666\n",
            "e: 7 tensor(555.8212, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.480778452685422\n",
            "e: 8 tensor(537.9424, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.500559462915601\n",
            "e: 9 tensor(524.3246, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.5127677429667519\n",
            "e: 10 tensor(512.3017, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.5245164641943734\n",
            "e: 11 tensor(499.0322, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.5380634590792839\n",
            "e: 12 tensor(487.7459, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.5488730818414322\n",
            "e: 13 tensor(475.6830, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.5588235294117647\n",
            "e: 14 tensor(466.1291, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.5698729219948849\n",
            "e: 15 tensor(456.8694, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.576266783887468\n",
            "e: 16 tensor(448.4030, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.5854379795396419\n",
            "e: 17 tensor(442.6352, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.594988810741688\n",
            "e: 18 tensor(433.9272, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.5994245524296675\n",
            "e: 19 tensor(426.4104, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.6074768222506394\n",
            "e: 20 tensor(420.0347, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.6123721227621484\n",
            "e: 21 tensor(414.7898, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.6190257352941176\n",
            "e: 22 tensor(407.7513, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.6249000959079284\n",
            "e: 23 tensor(401.4610, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.6309942455242967\n",
            "e: 24 tensor(394.9464, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.6386069373401535\n",
            "e: 25 tensor(388.6363, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.6436221227621484\n",
            "e: 26 tensor(381.7825, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.6503556585677749\n",
            "e: 27 tensor(376.0040, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.6560501918158568\n",
            "e: 28 tensor(372.8606, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.6588674872122762\n",
            "e: 29 tensor(365.6302, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.6658208120204604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing(dnn = dnn, unet=unet, criterion = loss_fn, test_loader = testloader,  use_cuda = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_TR9kt7LJl3",
        "outputId": "5a766a6a-9170-490c-ab89-8478f4ec1e04"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: tensor(81.8390, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.6234177215189873\n"
          ]
        }
      ]
    }
  ]
}