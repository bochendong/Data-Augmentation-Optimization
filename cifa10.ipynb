{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "S6EW9VQe4-Sx"
      ],
      "authorship_tag": "ABX9TyMvTmvTo3sAl+0F9zc94pu7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bochendong/giao_bochen/blob/main/cifa10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ee58nKM9tSpJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import random\n",
        "from torchvision.utils import save_image\n",
        "import os\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Prepare"
      ],
      "metadata": {
        "id": "BpdsolAZtynW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Train_BASE_UNET = False\n",
        "Train_BASE_DNN = False\n",
        "Train_Model = True\n",
        "MODEL_PATH = 'model_weight/unet.pth'\n",
        "Base_UNET_PATH = 'model_weight/base_unet.pth'\n",
        "DNN_PATH = 'model_weight/dnn.pth'"
      ],
      "metadata": {
        "id": "-H03plXaEKqU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "p6q1zursEMP1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''if (os.path.exists(MODEL_PATH)) == True:\n",
        "    Train_Model = False'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "keYjzxWpENWS",
        "outputId": "b14f7ed8-969c-4fb5-ba74-1b2f76498383"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'if (os.path.exists(MODEL_PATH)) == True:\\n    Train_Model = False'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if (os.path.exists(\"./output\")) == False:\n",
        "    os.mkdir(\"output\")\n",
        "\n",
        "if (os.path.exists(\"./model_weight\")) == False:\n",
        "    os.mkdir(\"model_weight\")\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 100\n",
        "\n",
        "for epoch in range (EPOCHS):\n",
        "    if (os.path.exists(\"./output/%03d\" % epoch)) == False:\n",
        "        os.mkdir(\"./output/%03d\" % epoch)\n",
        "    else:\n",
        "        files = glob.glob(\"./output/%03d/*.png\" % epoch)\n",
        "\n",
        "        for f in files:\n",
        "          os.remove(f)"
      ],
      "metadata": {
        "id": "9cZyGvc4tUNt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=1)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRk-EOEStXEF",
        "outputId": "8eaecfed-76d3-48dd-8427-32d85d5fa63f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_iter = iter(trainloader)\n",
        "test_img, test_label = next(dataset_iter)"
      ],
      "metadata": {
        "id": "7IDif9wEvd1H"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToxjirKdv5Vy",
        "outputId": "ff606bfe-0aaf-4c81-81c7-df5521c60ffd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_label.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlK6kry6v6d8",
        "outputId": "82463789-ab3b-44d5-faa3-d1ed19587a64"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unet"
      ],
      "metadata": {
        "id": "MDAUsl5ttdj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "        self.activate = nn.ReLU(inplace=True)\n",
        "        self.pool = nn.MaxPool2d((2, 2))\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.sigmod = nn.Sigmoid ()\n",
        "\n",
        "        self.encoder_1_0 = nn.Conv2d(3, 64, 3, padding= 1)\n",
        "        self.encoder_1_1 = nn.Conv2d(64, 64, 3, padding= 1)\n",
        "\n",
        "        self.encoder_2_0 = nn.Conv2d(64, 128, 3, padding= 1)\n",
        "        self.encoder_2_1 = nn.Conv2d(128, 128, 3, padding= 1)\n",
        "\n",
        "        self.encoder_3_0 = nn.Conv2d(128, 256, 3, padding= 1)\n",
        "        self.encoder_3_1 = nn.Conv2d(256, 256, 3, padding= 1)\n",
        "\n",
        "        self.encoder_4_0 = nn.Conv2d(256, 512, 3, padding= 1)\n",
        "        self.encoder_4_1 = nn.Conv2d(512, 512, 3, padding= 1)\n",
        "\n",
        "        self.middle_1_0 = nn.Conv2d(512, 1024, 3, padding= 1)\n",
        "        self.middle_1_1 = nn.Conv2d(1024, 1024, 3, padding= 1)\n",
        "\n",
        "        self.deconv4_0 = nn.ConvTranspose2d(1024, 512, 3, stride=(2,2), padding = 1, output_padding = 1)\n",
        "        self.uconv4_1 = nn.Conv2d(1024, 512, 3, padding= 1) \n",
        "        self.uconv4_2 = nn.Conv2d(512, 512, 3, padding= 1)\n",
        "\n",
        "        self.deconv3_0 = nn.ConvTranspose2d(512, 512, 3, stride=(2,2), padding = 1, output_padding = 1)\n",
        "        self.uconv3_1 = nn.Conv2d(768, 256, 3, padding= 1) \n",
        "        self.uconv3_2 = nn.Conv2d(256, 256, 3, padding= 1)\n",
        "\n",
        "        self.deconv2_0 = nn.ConvTranspose2d(256, 512, 3, stride=(2,2), padding = 1, output_padding = 1)\n",
        "        self.uconv2_1 = nn.Conv2d(640, 128, 3, padding= 1) \n",
        "        self.uconv2_2 = nn.Conv2d(128, 128, 3, padding= 1)\n",
        "\n",
        "        self.deconv1_0 = nn.ConvTranspose2d(128, 512, 3, stride=(2,2), padding = 1, output_padding = 1)\n",
        "        self.uconv1_1 = nn.Conv2d(576, 192, 3, padding= 1) \n",
        "        self.uconv1_2 = nn.Conv2d(192, 192, 3, padding= 1)\n",
        "\n",
        "        self.out_layer = nn.Conv2d(192, 3, 1)\n",
        " \n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1 = self.encoder_1_0(x)\n",
        "        conv1 = self.activate(conv1)\n",
        "        conv1 = self.encoder_1_1(conv1)\n",
        "        conv1 = self.activate(conv1)\n",
        "\n",
        "        pool1 = self.pool(conv1)\n",
        "        pool1 = self.dropout(pool1)\n",
        "\n",
        "        conv2 = self.encoder_2_0(pool1)\n",
        "        conv2 = self.activate(conv2)\n",
        "        conv2 = self.encoder_2_1(conv2)\n",
        "        conv2 = self.activate(conv2)\n",
        "\n",
        "        pool2 = self.pool(conv2)\n",
        "        pool2 = self.dropout(pool2)\n",
        "\n",
        "        conv3 = self.encoder_3_0(pool2)\n",
        "        conv3 = self.activate(conv3)\n",
        "        conv3 = self.encoder_3_1(conv3)\n",
        "        conv3 = self.activate(conv3)\n",
        "\n",
        "        pool3 = self.pool(conv3)\n",
        "        pool3 = self.dropout(pool3)\n",
        "\n",
        "        conv4 = self.encoder_4_0(pool3)\n",
        "        conv4 = self.activate(conv4)\n",
        "        conv4 = self.encoder_4_1(conv4)\n",
        "        conv4 = self.activate(conv4)\n",
        "\n",
        "        pool4 = self.pool(conv4)\n",
        "        pool4 = self.dropout(pool4)\n",
        "\n",
        "        convm = self.middle_1_0(pool4)\n",
        "        convm = self.activate(convm)\n",
        "        convm = self.middle_1_1(convm)\n",
        "        convm = self.activate(convm)\n",
        "\n",
        "        deconv4 = self.deconv4_0(convm)           # (None, 4, 4, 512)\n",
        "        uconv4 = torch.cat([deconv4, conv4], 1)   # (None, 4, 4, 1024)\n",
        "        uconv4 = self.dropout(uconv4)\n",
        "        uconv4 = self.uconv4_1(uconv4)            # (None, 4, 4, 512)\n",
        "        uconv4 = self.activate(uconv4)\n",
        "        uconv4 = self.uconv4_2(uconv4)            # (None, 4, 4, 512)\n",
        "        uconv4 = self.activate(uconv4)\n",
        "\n",
        "        deconv3 = self.deconv3_0(uconv4)          # (None, 8, 8, 512)\n",
        "        uconv3 = torch.cat([deconv3, conv3], 1)   # (None, 8, 8, 768)\n",
        "        uconv3 = self.dropout(uconv3)\n",
        "        uconv3 = self.uconv3_1(uconv3)            # (None, 8, 8, 256)\n",
        "        uconv3 = self.activate(uconv3)\n",
        "        uconv3 = self.uconv3_2(uconv3)            # (None, 8, 8, 256)\n",
        "        uconv3 = self.activate(uconv3)\n",
        "        \n",
        "        deconv2 = self.deconv2_0(uconv3)          # (None, 16, 16, 512)\n",
        "        uconv2 = torch.cat([deconv2, conv2], 1)   # (None, 16, 16, 640)\n",
        "        uconv2 = self.dropout(uconv2)\n",
        "        uconv2 = self.uconv2_1(uconv2)            # (None, 16, 16, 128)\n",
        "        uconv2 = self.activate(uconv2)\n",
        "        uconv2 = self.uconv2_2(uconv2)            # (None, 16, 16, 128)\n",
        "        uconv2 = self.activate(uconv2)\n",
        "\n",
        "        deconv1 = self.deconv1_0(uconv2)          # (None, 32, 32, 512)\n",
        "        uconv1 = torch.cat([deconv1, conv1], 1)   # (None, 32, 32, 576)\n",
        "        uconv1 = self.dropout(uconv1)\n",
        "        uconv1 = self.uconv1_1(uconv1)            # (None, 32, 32, 192)\n",
        "        uconv1 = self.activate(uconv1)\n",
        "        uconv1 = self.uconv1_2(uconv1)            # (None, 32, 32, 192)\n",
        "        uconv1 = self.activate(uconv1)\n",
        "\n",
        "        out = self.out_layer(uconv1)\n",
        "        out = self.activate(out)\n",
        "        return out\n",
        "     "
      ],
      "metadata": {
        "id": "frT_ZkVmtY61"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_training(model, train_loader, loss_fn, optimizer, epoch, use_cuda = True):\n",
        "    dataset_iter = iter(train_loader)\n",
        "    len_dataloader = len(dataset_iter)\n",
        "\n",
        "    i = 0\n",
        "    loss_sum = 0\n",
        "    while i < len_dataloader:\n",
        "        img, true_label = next(dataset_iter)\n",
        "        optimizer.zero_grad()\n",
        "        if use_cuda:\n",
        "            img, true_label = img.cuda(), true_label.cuda()\n",
        "\n",
        "        recon = model(img)\n",
        "        loss = loss_fn(recon, img)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_sum += loss\n",
        "\n",
        "        if  i % 100 == 0:\n",
        "            real = img.data\n",
        "            reconstruction= recon.data\n",
        "\n",
        "            save_image(real, './output/%03d/%d_A.png' % ( epoch, i))\n",
        "            save_image(reconstruction, 'output/%03d/%d_reconA.png' % ( epoch, i))\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    print(\"e:\", epoch, loss_sum)\n"
      ],
      "metadata": {
        "id": "Q8-1aPa_wYe8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if (Train_BASE_UNET):\n",
        "    unet = UNet()\n",
        "\n",
        "    learning_rate = 1e-4\n",
        "    optimizer = torch.optim.Adam(unet.parameters(), lr=learning_rate)\n",
        "    recon_loss_fn = nn.L1Loss()\n",
        "\n",
        "    if (torch.cuda.is_available()):\n",
        "        recon_loss_fn = recon_loss_fn.cuda()\n",
        "        unet.cuda()\n",
        "\n",
        "    for e in range(30):\n",
        "        unet_training(model=unet, train_loader = trainloader, \n",
        "                    loss_fn = recon_loss_fn, optimizer = optimizer, \n",
        "                    epoch = e, use_cuda = True)\n",
        "        \n",
        "    torch.save(unet.state_dict(), Base_UNET_PATH)"
      ],
      "metadata": {
        "id": "U6RmGup_wyzE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DNN"
      ],
      "metadata": {
        "id": "S6EW9VQe4-Sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "FKbLd1LJ4dbN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dnn_training(dnn, train_loader, criterion, optimizer, epoch, use_cuda):\n",
        "    dataset_iter = iter(train_loader)\n",
        "    len_dataloader = len(dataset_iter)\n",
        "\n",
        "    i = 0\n",
        "    loss_sum = 0\n",
        "    total = 0\n",
        "    correct_label = 0\n",
        "\n",
        "    while i < len_dataloader:\n",
        "        total += BATCH_SIZE\n",
        "        img, true_label = next(dataset_iter)\n",
        "        optimizer.zero_grad()\n",
        "        if use_cuda:\n",
        "            img, true_label = img.cuda(), true_label.cuda()\n",
        "\n",
        "        y_pred_on_recon = dnn(img)\n",
        "        loss = criterion(y_pred_on_recon, true_label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_sum += loss\n",
        "\n",
        "        _, predicted = torch.max(y_pred_on_recon.data, 1)\n",
        "        correct_label += predicted.eq(true_label.data).cpu().sum().item()\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    print(\"e:\", epoch, loss_sum, 'acc: ', correct_label/total)\n"
      ],
      "metadata": {
        "id": "HMTcWnDw4q9i"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if (Train_BASE_DNN):\n",
        "    baseline = DNN()\n",
        "    learning_rate = 1e-4\n",
        "    optimizer = torch.optim.Adam(baseline.parameters(), lr=learning_rate)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    if (torch.cuda.is_available()):\n",
        "        torch.cuda.manual_seed_all(42)\n",
        "        loss_fn = loss_fn.cuda()\n",
        "        baseline.cuda()\n",
        "\n",
        "    for e in range(EPOCHS):\n",
        "        dnn_training(dnn = baseline,\n",
        "                    train_loader = trainloader, \n",
        "                    criterion = loss_fn, \n",
        "                    optimizer = optimizer, \n",
        "                    epoch = e,\n",
        "                    use_cuda = True)\n",
        "        \n",
        "        torch.save(unet.state_dict(), DNN_PATH)"
      ],
      "metadata": {
        "id": "QnuUDvFP4hGO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pred on reconstruct"
      ],
      "metadata": {
        "id": "f0bgtgVWIpp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training(dnn, unet, train_loader, loss_fn, recon_loss_fn, optimizer_dnn, optimizer_unet, epoch, use_cuda):\n",
        "    dataset_iter = iter(train_loader)\n",
        "    len_dataloader = len(dataset_iter)\n",
        "\n",
        "    i = 0\n",
        "    loss_sum = 0\n",
        "    total = 0\n",
        "    correct_label = 0\n",
        "\n",
        "    while i < len_dataloader:\n",
        "        total += BATCH_SIZE\n",
        "        img, true_label = next(dataset_iter)\n",
        "        optimizer_dnn.zero_grad()\n",
        "        optimizer_unet.zero_grad()\n",
        "        if use_cuda:\n",
        "            img, true_label = img.cuda(), true_label.cuda()\n",
        "\n",
        "        recon = unet(img)\n",
        "        y_pred_on_recon = dnn(recon)\n",
        "\n",
        "        loss_recon = recon_loss_fn(recon, img)\n",
        "        loss = loss_fn(y_pred_on_recon, true_label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer_dnn.step()\n",
        "        optimizer_unet.step()\n",
        "        loss_sum += loss\n",
        "\n",
        "        _, predicted = torch.max(y_pred_on_recon.data, 1)\n",
        "        correct_label += predicted.eq(true_label.data).cpu().sum().item()\n",
        "\n",
        "        if  i % 100 == 0:\n",
        "            real = img.data\n",
        "            reconstruction= recon.data\n",
        "\n",
        "            save_image(real, './output/%03d/%d_A.png' % ( epoch, i))\n",
        "            save_image(reconstruction, 'output/%03d/%d_reconA.png' % ( epoch, i))\n",
        "\n",
        "        i += 1\n",
        "    print(\"e:\", epoch, loss_sum, 'acc: ', correct_label/total)\n",
        "\n",
        "def testing(dnn, unet, criterion, test_loader, use_cuda):\n",
        "    dataset_iter = iter(test_loader)\n",
        "    len_dataloader = len(dataset_iter)\n",
        "\n",
        "    i = 0\n",
        "    loss_sum = 0\n",
        "    total = 0\n",
        "    correct_label = 0\n",
        "\n",
        "    while i < len_dataloader:\n",
        "        total += BATCH_SIZE\n",
        "        img, true_label = next(dataset_iter)\n",
        "\n",
        "        if use_cuda:\n",
        "            img, true_label = img.cuda(), true_label.cuda()\n",
        "\n",
        "        recon = unet(img)\n",
        "        y_pred_on_recon = dnn(recon)\n",
        "\n",
        "        loss = criterion(y_pred_on_recon, true_label)\n",
        "        loss_sum += loss\n",
        "\n",
        "        _, predicted = torch.max(y_pred_on_recon.data, 1)\n",
        "        correct_label += predicted.eq(true_label.data).cpu().sum().item()\n",
        "\n",
        "        i += 1\n",
        "    print(\"Testing:\", loss_sum, 'acc: ', correct_label/total)"
      ],
      "metadata": {
        "id": "SlhTVPKLIpLF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if (Train_Model):\n",
        "    dnn = DNN()\n",
        "    unet = UNet()\n",
        "\n",
        "    learning_rate = 1e-4\n",
        "\n",
        "    optimizer_dnn = torch.optim.Adam(dnn.parameters(), lr=learning_rate)\n",
        "    optimizer_unet = torch.optim.Adam(unet.parameters(), lr=learning_rate)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    recon_loss_fn = nn.MSELoss()\n",
        "\n",
        "    if (torch.cuda.is_available()):\n",
        "        torch.cuda.manual_seed_all(42)\n",
        "        loss_fn = loss_fn.cuda()\n",
        "        recon_loss_fn = recon_loss_fn.cuda()\n",
        "        dnn.cuda()\n",
        "        unet.cuda()\n",
        "\n",
        "    for e in range(EPOCHS):\n",
        "        training(dnn = dnn,\n",
        "                    unet=unet,\n",
        "                    train_loader = trainloader, \n",
        "                    loss_fn = loss_fn, \n",
        "                    recon_loss_fn = recon_loss_fn,\n",
        "                    optimizer_dnn = optimizer_dnn, \n",
        "                    optimizer_unet = optimizer_unet,\n",
        "                    epoch = e,\n",
        "                    use_cuda = True)\n",
        "        \n",
        "    torch.save(unet.state_dict(), MODEL_PATH)"
      ],
      "metadata": {
        "id": "DFf_Na9KIwc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4324627f-150f-4c20-ba74-c31a6b181d11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e: 0 tensor(844.0641, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.22068813938618925\n",
            "e: 1 tensor(695.2189, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.3813139386189258\n",
            "e: 2 tensor(627.8627, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.4527653452685422\n",
            "e: 3 tensor(567.7477, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.5117886828644501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Showcase"
      ],
      "metadata": {
        "id": "8UDsv-AyDHid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unet = UNet()\n",
        "unet.load_state_dict(torch.load(MODEL_PATH))"
      ],
      "metadata": {
        "id": "L8-EziJmB0Me"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo_iter = iter(testloader)\n",
        "demo_img, demo_label = next(demo_iter)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    demo_img = demo_img.cuda()\n",
        "    unet.cuda()\n",
        "\n",
        "recon = unet(demo_img)\n",
        "recon = recon.data.cpu().detach()\n",
        "demo_img = demo_img.data.cpu().detach()\n",
        "demo_label = demo_label.numpy()\n"
      ],
      "metadata": {
        "id": "EA35Icv04t8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recon_imgs = [[], [], [], [], [], [], [], [], [], []]\n",
        "real_imgs = [[], [], [], [], [], [], [], [], [], []]"
      ],
      "metadata": {
        "id": "cBcxKtiSUbYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, label in enumerate(demo_label):\n",
        "\n",
        "    recon_img = recon[i].transpose(0,2).transpose(0,1)\n",
        "    real_img = demo_img[i].transpose(0,2).transpose(0,1)\n",
        "\n",
        "    recon_imgs[label].append(recon_img)\n",
        "    real_imgs[label].append(real_img)\n",
        "  "
      ],
      "metadata": {
        "id": "RRZAAq4-Urlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(10, 10, figsize=(12, 12))\n",
        "\n",
        "for i in range (5):\n",
        "    for j in range (5):\n",
        "      axs[i * 2][j].imshow(recon_imgs[i][j])\n",
        "      axs[i * 2 + 1][j].imshow(real_imgs[i][j])\n",
        "\n",
        "for i in range (5):\n",
        "    for j in range (5):\n",
        "      axs[i * 2][j + 5].imshow(recon_imgs[i + 5][j])\n",
        "      axs[i * 2 + 1][j + 5].imshow(real_imgs[i + 5][j])"
      ],
      "metadata": {
        "id": "Q52gEQD3U--S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Z5XvbWo-SfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dnn_testing(dnn, test_loader, criterion, use_cuda):\n",
        "    dataset_iter = iter(test_loader)\n",
        "    len_dataloader = len(dataset_iter)\n",
        "\n",
        "    i = 0\n",
        "    loss_sum = 0\n",
        "    total = 0\n",
        "    correct_label = 0\n",
        "\n",
        "    while i < len_dataloader:\n",
        "        total += BATCH_SIZE\n",
        "        img, true_label = next(dataset_iter)\n",
        "\n",
        "        if use_cuda:\n",
        "            img, true_label = img.cuda(), true_label.cuda()\n",
        "\n",
        "        y_pred = dnn(img)\n",
        "        loss = criterion(y_pred, true_label)\n",
        "\n",
        "        optimizer.step()\n",
        "        loss_sum += loss\n",
        "\n",
        "        _, predicted = torch.max(y_pred.data, 1)\n",
        "        correct_label += predicted.eq(true_label.data).cpu().sum().item()\n",
        "\n",
        "        i += 1\n",
        "\n",
        "    print(\"testing:\", loss_sum, 'acc: ', correct_label/total)"
      ],
      "metadata": {
        "id": "fmfVTzJI-Rx-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}