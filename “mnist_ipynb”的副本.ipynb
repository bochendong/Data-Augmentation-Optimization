{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bochendong/giao_bochen/blob/main/%E2%80%9Cmnist_ipynb%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_JxnsWA192d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import random\n",
        "from torchvision.utils import save_image\n",
        "import os\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evQnM7Yy192e"
      },
      "outputs": [],
      "source": [
        "if (os.path.exists(\"./output\")) == False:\n",
        "    os.mkdir(\"output\")\n",
        "\n",
        "if (os.path.exists(\"./model_weight\")) == False:\n",
        "    os.mkdir(\"model_weight\")\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 15\n",
        "\n",
        "for epoch in range (EPOCHS):\n",
        "    if (os.path.exists(\"./output/%03d\" % epoch)) == False:\n",
        "        os.mkdir(\"./output/%03d\" % epoch)\n",
        "    else:\n",
        "        files = glob.glob(\"./output/%03d/*.png\" % epoch)\n",
        "\n",
        "        for f in files:\n",
        "          os.remove(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiagpDer192e"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93UoHc_R192e"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('data', train=True, download=True, \n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,)),\n",
        "                           transforms.Resize(32)\n",
        "                       ])),\n",
        "        batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,)),\n",
        "                           transforms.Resize(32)\n",
        "                       ])),\n",
        "        batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xc8G4-o8192f"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size = 3)\n",
        "        self.relu  = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size = 3)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.relu(self.conv2(self.relu(self.conv1(x))))\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, chs=(1, 64, 128)):\n",
        "        super().__init__()\n",
        "        self.enc_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)])\n",
        "        self.pool       = nn.MaxPool2d(2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        ftrs = []\n",
        "        for block in self.enc_blocks:\n",
        "            x = block(x)\n",
        "            ftrs.append(x)\n",
        "            x = self.pool(x)\n",
        "        return ftrs\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, chs=(128, 64)):\n",
        "        super().__init__()\n",
        "        self.chs         = chs\n",
        "        self.upconvs    = nn.ModuleList([nn.ConvTranspose2d(chs[i], chs[i+1], 2, 2) for i in range(len(chs)-1)])\n",
        "        self.dec_blocks = nn.ModuleList([Block(chs[i], chs[i+1]) for i in range(len(chs)-1)]) \n",
        "        \n",
        "    def forward(self, x, encoder_features):\n",
        "        for i in range(len(self.chs)-1):\n",
        "            x        = self.upconvs[i](x)\n",
        "            enc_ftrs = self.crop(encoder_features[i], x)\n",
        "            x        = torch.cat([x, enc_ftrs], dim=1)\n",
        "            x        = self.dec_blocks[i](x)\n",
        "        return x\n",
        "    \n",
        "    def crop(self, enc_ftrs, x):\n",
        "        _, _, H, W = x.shape\n",
        "        enc_ftrs   = torchvision.transforms.CenterCrop([H, W])(enc_ftrs)\n",
        "        return enc_ftrs\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, enc_chs=(1, 64, 128), dec_chs=(128, 64), \n",
        "                    num_class=1, retain_dim=True, out_sz=(32,32)):\n",
        "        super().__init__()\n",
        "        self.encoder     = Encoder(enc_chs)\n",
        "        self.decoder     = Decoder(dec_chs)\n",
        "        self.head        = nn.Conv2d(dec_chs[-1], num_class, 1)\n",
        "\n",
        "        self.retain_dim  = retain_dim\n",
        "        self.out_sz      = out_sz\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc_ftrs = self.encoder(x)\n",
        "        out      = self.decoder(enc_ftrs[::-1][0], enc_ftrs[::-1][1:])\n",
        "        out      = self.head(out)\n",
        "        if self.retain_dim:\n",
        "            out = F.interpolate(out, self.out_sz)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc_1 = nn.Linear(32 * 32, 512)\n",
        "        self.fc_2 = nn.Linear(512, 256)\n",
        "        self.fc_3 = nn.Linear(256, 10)\n",
        "        self.activate = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = x.view(-1, 32 * 32)\n",
        "      out = self.fc_1(x)\n",
        "      out = self.activate(out)\n",
        "      out = self.fc_2(out)\n",
        "      out = self.activate(out)\n",
        "      out = self.fc_3(out)\n",
        "\n",
        "      return out"
      ],
      "metadata": {
        "id": "tQ_Qp1kQ3JFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training(dnn, unet, train_loader, criterion, recon_criterion, optimizer_dnn, optimizer_unet, epoch, use_cuda):\n",
        "    dataset_iter = iter(train_loader)\n",
        "    len_dataloader = len(dataset_iter)\n",
        "\n",
        "    i = 0\n",
        "    loss_sum = 0\n",
        "    total = 0\n",
        "    correct_label = 0\n",
        "\n",
        "    while i < len_dataloader:\n",
        "        total += BATCH_SIZE\n",
        "        img, true_label = next(dataset_iter)\n",
        "        optimizer_dnn.zero_grad()\n",
        "        optimizer_unet.zero_grad()\n",
        "        if use_cuda:\n",
        "            img, true_label = img.cuda(), true_label.cuda()\n",
        "\n",
        "        recon = unet(img)\n",
        "        y_pred_on_recon = dnn(recon)\n",
        "\n",
        "        loss = criterion(y_pred_on_recon, true_label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer_dnn.step()\n",
        "        optimizer_unet.step()\n",
        "        loss_sum += loss\n",
        "\n",
        "        _, predicted = torch.max(y_pred_on_recon.data, 1)\n",
        "        correct_label += predicted.eq(true_label.data).cpu().sum().item()\n",
        "\n",
        "        if  i % 100 == 0:\n",
        "            real = img.data\n",
        "            reconstruction= recon.data\n",
        "\n",
        "            save_image(real, './output/%03d/%d_A.png' % ( epoch, i))\n",
        "            save_image(reconstruction, 'output/%03d/%d_reconA.png' % ( epoch, i))\n",
        "\n",
        "        i += 1\n",
        "    print(\"e:\", epoch, loss_sum, 'acc: ', correct_label/total)"
      ],
      "metadata": {
        "id": "bvCRIw054e8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dnn = DNN()\n",
        "unet = UNet()\n",
        "\n",
        "learning_rate = 1e-4\n",
        "\n",
        "optimizer = torch.optim.Adam(dnn.parameters(), lr=learning_rate)\n",
        "optimizer_unet = torch.optim.Adam(unet.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "recon_loss = nn.MSELoss()"
      ],
      "metadata": {
        "id": "f_7PygLs6Fce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if (torch.cuda.is_available()):\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "    loss_fn = loss_fn.cuda()\n",
        "    recon_loss = recon_loss.cuda()\n",
        "    dnn.cuda()\n",
        "    unet.cuda()"
      ],
      "metadata": {
        "id": "rq8UjtT16GPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for e in range(EPOCHS):\n",
        "    training(dnn = dnn,\n",
        "                 unet=unet,\n",
        "                 train_loader = train_loader, \n",
        "                 criterion = loss_fn, \n",
        "                 recon_criterion = recon_loss,\n",
        "                 optimizer_dnn = optimizer, \n",
        "                 optimizer_unet = optimizer_unet,\n",
        "                 epoch = e,\n",
        "                 use_cuda = True)"
      ],
      "metadata": {
        "id": "oew1vZMc5BRz",
        "outputId": "24f86996-076d-4339-f441-c2ef3c6b2fa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e: 0 tensor(425.2411, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.93115\n",
            "e: 1 tensor(151.7661, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.9751833333333333\n",
            "e: 2 tensor(107.7781, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.9816166666666667\n",
            "e: 3 tensor(81.1118, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.9864\n",
            "e: 4 tensor(64.6139, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.98895\n",
            "e: 5 tensor(54.5813, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.9906166666666667\n",
            "e: 6 tensor(47.5059, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.9917166666666667\n",
            "e: 7 tensor(37.6757, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.9933333333333333\n",
            "e: 8 tensor(33.0212, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.9945333333333334\n",
            "e: 9 tensor(28.9382, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.9948833333333333\n",
            "e: 10 tensor(26.3884, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.99535\n",
            "e: 11 tensor(22.7213, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.996\n",
            "e: 12 tensor(20.3587, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.9966833333333334\n",
            "e: 13 tensor(20.2203, device='cuda:0', grad_fn=<AddBackward0>) acc:  0.9966333333333334\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-bb73d30297b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     DNN_training(dnn = dnn,\n\u001b[0m\u001b[1;32m      3\u001b[0m                  \u001b[0munet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                  \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                  \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-c57d0de7d8d5>\u001b[0m in \u001b[0;36mDNN_training\u001b[0;34m(dnn, unet, train_loader, criterion, recon_criterion, optimizer_dnn, optimizer_unet, epoch, use_cuda)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moptimizer_dnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer_unet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             adam(params_with_grad,\n\u001b[0m\u001b[1;32m    235\u001b[0m                  \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                  \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    301\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def testing(dnn, unet, test_loader, use_cuda):\n",
        "    dataset_iter = iter(test_loader)\n",
        "    len_dataloader = len(dataset_iter)\n",
        "\n",
        "    i = 0\n",
        "    loss_sum = 0\n",
        "    total = 0\n",
        "    correct_label = 0\n",
        "\n",
        "    while i < len_dataloader:\n",
        "        total += BATCH_SIZE\n",
        "        img, true_label = next(dataset_iter)\n",
        "\n",
        "        if use_cuda:\n",
        "            img, true_label = img.cuda(), true_label.cuda()\n",
        "\n",
        "        recon = unet(img)\n",
        "        y_pred_on_recon = dnn(recon)\n",
        "\n",
        "        loss = criterion(y_pred_on_recon, true_label)\n",
        "        loss_sum += loss\n",
        "\n",
        "        _, predicted = torch.max(y_pred_on_recon.data, 1)\n",
        "        correct_label += predicted.eq(true_label.data).cpu().sum().item()\n",
        "\n",
        "        i += 1\n",
        "    print(\"Testing:\", epoch, loss_sum, 'acc: ', correct_label/total)"
      ],
      "metadata": {
        "id": "KuQslKT-TEnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing(dnn = dnn, unet=unet, test_loader = test_loader,  use_cuda = True)"
      ],
      "metadata": {
        "id": "GNj7m9K5Tl-4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}