{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTZvbiBWoPPuOEFkHeYRJw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bochendong/giao_bochen/blob/main/unet_recon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JNobKD6qOv0F"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "import numpy as np\n",
        "import random\n",
        "from torchvision.utils import save_image\n",
        "import os\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import glob\n",
        "import cv2\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = 'model_weight/unet.pth'\n",
        "Base_UNET_PATH = 'model_weight/base_unet.pth'\n",
        "DNN_PATH = 'model_weight/dnn.pth'\n",
        "\n",
        "Train_BASE_DNN = True\n",
        "\n",
        "if (os.path.exists(DNN_PATH)) == True:\n",
        "    Train_BASE_DNN = False\n",
        "    \n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "MNIST = True\n",
        "CIFAR10 = False"
      ],
      "metadata": {
        "id": "aEdWVnk6OxfA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if (os.path.exists(\"./output\")) == False:\n",
        "    os.mkdir(\"output\")\n",
        "\n",
        "if (os.path.exists(\"./model_weight\")) == False:\n",
        "    os.mkdir(\"model_weight\")\n",
        "EPOCHS = 100\n",
        "for epoch in range (EPOCHS):\n",
        "    if (os.path.exists(\"./output/%03d\" % epoch)) == False:\n",
        "        os.mkdir(\"./output/%03d\" % epoch)\n",
        "    else:\n",
        "        files = glob.glob(\"./output/%03d/*.png\" % epoch)\n",
        "\n",
        "        for f in files:\n",
        "          os.remove(f)"
      ],
      "metadata": {
        "id": "aoS2SAgKUvAP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "BATCH_SIZE = 128\n",
        "learning_rate = 1e-6\n",
        "num_epochs = 20\n",
        "\n",
        "train_dataset = datasets.MNIST('data', train=True, download=True, \n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.Resize(32),\n",
        "                           transforms.ToTensor()\n",
        "                       ]))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
        "\n",
        "test_dataset =  datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
        "                           transforms.Resize(32),\n",
        "                           transforms.ToTensor()\n",
        "                       ]))\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)"
      ],
      "metadata": {
        "id": "2RmKeDRyVPiy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG11(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGG11, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "L58MlhB4jwjX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if (Train_BASE_DNN):\n",
        "    dnn_model = VGG11().cuda()\n",
        "    dnn_criterion = nn.CrossEntropyLoss()\n",
        "    dnn_optimizer = torch.optim.Adam(dnn_model.parameters(), lr=1e-5)\n",
        "\n",
        "    print(\"Training DNN classifier...\")\n",
        "    for epoch in range(10):\n",
        "            for i, (images, labels) in enumerate(train_loader):\n",
        "                images = images.cuda()\n",
        "                labels = labels.cuda()\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = dnn_model(images)\n",
        "                loss = dnn_criterion(outputs, labels)\n",
        "\n",
        "                # Backward pass and optimization\n",
        "                dnn_optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                dnn_optimizer.step()\n",
        "\n",
        "    print(\"DNN classifier training complete.\")\n",
        "    torch.save(dnn_model.state_dict(), DNN_PATH)"
      ],
      "metadata": {
        "id": "VsNfg0dZj0jd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "        self.activate = nn.ReLU(inplace=True)\n",
        "        self.pool = nn.MaxPool2d((2, 2))\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.sigmod = nn.Sigmoid ()\n",
        "        self.label_embedding = nn.Embedding(10, 512)\n",
        "\n",
        "        self.encoder_1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 3, padding= 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, 3, padding= 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        self.encoder_2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3, padding= 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, 3, padding= 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        self.encoder_3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, 3, padding= 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding= 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        self.encoder_4 = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, 3, padding= 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, 3, padding= 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        \n",
        "        self.middle_1_0 = nn.Conv2d(1024, 1024, 3, padding= 1)\n",
        "        self.middle_1_1 = nn.Conv2d(1024, 1024, 3, padding= 1)\n",
        "        \n",
        "       \n",
        "        self.deconv4_0 = nn.ConvTranspose2d(1536, 512, 3, stride=(2,2), padding = 1, output_padding = 1)\n",
        "        self.uconv4_1 = nn.Conv2d(1024, 512, 3, padding= 1) \n",
        "        self.uconv4_2 = nn.Conv2d(512, 512, 3, padding= 1)\n",
        "\n",
        "        self.deconv3_0 = nn.ConvTranspose2d(512, 512, 3, stride=(2,2), padding = 1, output_padding = 1)\n",
        "        self.uconv3_1 = nn.Conv2d(768, 256, 3, padding= 1) \n",
        "        self.uconv3_2 = nn.Conv2d(256, 256, 3, padding= 1)\n",
        "\n",
        "        self.deconv2_0 = nn.ConvTranspose2d(256, 512, 3, stride=(2,2), padding = 1, output_padding = 1)\n",
        "        self.uconv2_1 = nn.Conv2d(640, 128, 3, padding= 1) \n",
        "        self.uconv2_2 = nn.Conv2d(128, 128, 3, padding= 1)\n",
        "\n",
        "        self.deconv1_0 = nn.ConvTranspose2d(128, 512, 3, stride=(2,2), padding = 1, output_padding = 1)\n",
        "        self.uconv1_1 = nn.Conv2d(576, 192, 3, padding= 1) \n",
        "        self.uconv1_2 = nn.Conv2d(192, 192, 3, padding= 1)\n",
        "\n",
        "  \n",
        "        self.out_layer = nn.Conv2d(192, 1, 1)\n",
        "\n",
        " \n",
        "\n",
        "    def forward(self, x, input_labels, target_labels):\n",
        "        conv1 = self.encoder_1(x)\n",
        "        pool1 = self.pool(conv1)\n",
        "        pool1 = self.dropout(pool1)\n",
        "\n",
        "        conv2 = self.encoder_2(pool1)\n",
        "        pool2 = self.pool(conv2)\n",
        "        pool2 = self.dropout(pool2)\n",
        "\n",
        "        conv3 = self.encoder_3(pool2)\n",
        "        pool3 = self.pool(conv3)\n",
        "        pool3 = self.dropout(pool3)\n",
        "\n",
        "        conv4 = self.encoder_4(pool3)\n",
        "        pool4 = self.pool(conv4)\n",
        "        encoder_out = self.dropout(pool4)\n",
        "\n",
        "        input_label_embedding = self.label_embedding(input_labels).view(input_labels.size(0), 512, 1, 1)\n",
        "        x1 = torch.cat([encoder_out, input_label_embedding.expand_as(encoder_out)], dim=1)\n",
        "\n",
        "        convm = self.middle_1_0(x1)\n",
        "        convm = self.activate(convm)\n",
        "        convm = self.middle_1_1(convm)\n",
        "        x2 = self.activate(convm)\n",
        "\n",
        "        target_label_embedding = self.label_embedding(target_labels).view(target_labels.size(0), 512, 1, 1)\n",
        "        x2 = torch.cat([x2, target_label_embedding.expand(x2.size(0), 512, x2.size(2), x2.size(3))], dim=1)\n",
        "\n",
        "        deconv4 = self.deconv4_0(x2)\n",
        "        uconv4 = torch.cat([deconv4, conv4], 1)   # (None, 4, 4, 1024)\n",
        "        uconv4 = self.dropout(uconv4)\n",
        "        uconv4 = self.uconv4_1(uconv4)            # (None, 4, 4, 512)\n",
        "        uconv4 = self.activate(uconv4)\n",
        "        uconv4 = self.uconv4_2(uconv4)            # (None, 4, 4, 512)\n",
        "        uconv4 = self.activate(uconv4)\n",
        "\n",
        "        deconv3 = self.deconv3_0(uconv4)          # (None, 8, 8, 512)\n",
        "        uconv3 = torch.cat([deconv3, conv3], 1)   # (None, 8, 8, 768)\n",
        "        uconv3 = self.dropout(uconv3)\n",
        "        uconv3 = self.uconv3_1(uconv3)            # (None, 8, 8, 256)\n",
        "        uconv3 = self.activate(uconv3)\n",
        "        uconv3 = self.uconv3_2(uconv3)            # (None, 8, 8, 256)\n",
        "        uconv3 = self.activate(uconv3)\n",
        "        \n",
        "        deconv2 = self.deconv2_0(uconv3)          # (None, 16, 16, 512)\n",
        "        uconv2 = torch.cat([deconv2, conv2], 1)   # (None, 16, 16, 640)\n",
        "        uconv2 = self.dropout(uconv2)\n",
        "        uconv2 = self.uconv2_1(uconv2)            # (None, 16, 16, 128)\n",
        "        uconv2 = self.activate(uconv2)\n",
        "        uconv2 = self.uconv2_2(uconv2)            # (None, 16, 16, 128)\n",
        "        uconv2 = self.activate(uconv2)\n",
        "\n",
        "        deconv1 = self.deconv1_0(uconv2)          # (None, 32, 32, 512)\n",
        "        uconv1 = torch.cat([deconv1, conv1], 1)   # (None, 32, 32, 576)\n",
        "        uconv1 = self.dropout(uconv1)\n",
        "        uconv1 = self.uconv1_1(uconv1)            # (None, 32, 32, 192)\n",
        "        uconv1 = self.activate(uconv1)\n",
        "        uconv1 = self.uconv1_2(uconv1)            # (None, 32, 32, 192)\n",
        "        uconv1 = self.activate(uconv1)\n",
        "\n",
        "        out = self.out_layer(uconv1)\n",
        "        out = self.sigmod(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "OAnJ_g0hUHLH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''dataset_iter = iter(train_loader)\n",
        "test_img, test_label = next(dataset_iter)\n",
        "\n",
        "target_labels = (test_label + torch.randint(1, 9, size=(BATCH_SIZE,))) % 10\n",
        "\n",
        "model = UNet()\n",
        "model(test_img, test_label, target_labels).size()'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ZrzKVOk9bs0o",
        "outputId": "52a061d9-4163-4ff7-d1c7-1bcdd49b3d1b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dataset_iter = iter(train_loader)\\ntest_img, test_label = next(dataset_iter)\\n\\ntarget_labels = (test_label + torch.randint(1, 9, size=(BATCH_SIZE,))) % 10\\n\\nmodel = UNet()\\nmodel(test_img, test_label, target_labels).size()'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.5\n",
        "beta = 0.3\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "model = UNet().cuda()\n",
        "dnn_model = VGG11().cuda()\n",
        "dnn_model.load_state_dict(torch.load(DNN_PATH))\n",
        "dnn_criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Freeze the DNN classifier weights\n",
        "\n",
        "for param in dnn_model.parameters():\n",
        "    param.requires_grad = False\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "def perceptual_loss(vgg_model, input_images, output_images):\n",
        "    feature_layers = [vgg_model.features[i] for i in range(len(vgg_model.features))]\n",
        "    feature_extractor = nn.Sequential(*feature_layers[:-1]).cuda()\n",
        "    \n",
        "    input_features = feature_extractor(input_images)\n",
        "    output_features = feature_extractor(output_images)\n",
        "    \n",
        "    return nn.functional.mse_loss(input_features, output_features)\n",
        "\n",
        "def generate_synthetic_digits(digit, count):\n",
        "    digit_indices = np.where(train_dataset.targets.cpu() == digit.cpu())[0]\n",
        "    selected_indices = np.random.choice(digit_indices, count, replace=True)\n",
        "    synthetic_digits = torch.stack([train_dataset[i][0] for i in selected_indices])\n",
        "    return synthetic_digits\n",
        "\n",
        "# Erode the input images to remove the digit information\n",
        "def erode_images(images):\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
        "    eroded_images = []\n",
        "    for image in images:\n",
        "        gray_image = image.squeeze(0).detach().cpu().numpy()\n",
        "        eroded_image = cv2.erode(gray_image, kernel, iterations=1)\n",
        "        eroded_images.append(eroded_image)\n",
        "    \n",
        "    eroded_images_np = np.array(eroded_images)\n",
        "    return torch.tensor(eroded_images_np).unsqueeze(1).cuda()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    print('e:' , epoch)\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        target_labels = (labels + torch.randint(1, 9, size=(BATCH_SIZE,)).cuda()) % 10\n",
        "\n",
        "        outputs = model(images, labels, target_labels)\n",
        "        \n",
        "        # Generate target images (same digit as target labels)\n",
        "        eroded_images = erode_images(images)\n",
        "        synthetic_target_digits = torch.cat([generate_synthetic_digits(d, 1) for d in target_labels]).cuda()\n",
        "        target_images = (eroded_images + synthetic_target_digits) / 2\n",
        "\n",
        "        # Compute loss\n",
        "        reconstruction_loss = criterion(outputs, target_images)\n",
        "        classification_loss = dnn_criterion(dnn_model(outputs), target_labels)\n",
        "        p_loss = perceptual_loss(dnn_model, images, outputs)\n",
        "\n",
        "        loss = reconstruction_loss + alpha * classification_loss + beta * p_loss\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print('loss:' , loss.data.cpu().numpy(), 'recon loss:', reconstruction_loss.data.cpu().numpy(), \n",
        "                  'dnn loss:', alpha * classification_loss.data.cpu().numpy(), 'p loss:', beta * p_loss.data.cpu().numpy())\n",
        "            save_image(outputs.data, './output/%03d/%04d_recon.png' % ( epoch, i))\n",
        "            save_image(images.data, './output/%03d/%04d_img.png' % ( epoch, i))\n",
        "            save_image(target_images.data, './output/%03d/%04d_target.png' % ( epoch, i))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSTmXEBvVK_u",
        "outputId": "377c7fe7-1f17-4ef4-ce05-0cd2f5c6a02f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e: 0\n",
            "loss: 2.0692277 recon loss: 0.6637594 dnn loss: 1.4018771648406982 p loss: 0.0035910475999116898\n",
            "loss: 2.0944738 recon loss: 0.6565506 dnn loss: 1.4340968132019043 p loss: 0.003826374281197786\n",
            "loss: 2.049282 recon loss: 0.6399714 dnn loss: 1.4058438539505005 p loss: 0.003466800972819328\n",
            "loss: 1.7940049 recon loss: 0.4726147 dnn loss: 1.315889596939087 p loss: 0.005500556342303752\n",
            "e: 1\n",
            "loss: 1.6910516 recon loss: 0.45728853 dnn loss: 1.228514552116394 p loss: 0.005248581245541573\n",
            "loss: 1.660044 recon loss: 0.45274174 dnn loss: 1.201669692993164 p loss: 0.005632543936371803\n",
            "loss: 1.6430955 recon loss: 0.4372766 dnn loss: 1.2007369995117188 p loss: 0.005081843957304954\n",
            "loss: 1.6314642 recon loss: 0.45614552 dnn loss: 1.1698321104049683 p loss: 0.005486621148884296\n",
            "e: 2\n",
            "loss: 1.5765364 recon loss: 0.42718738 dnn loss: 1.1441315412521362 p loss: 0.005217593349516392\n",
            "loss: 1.413715 recon loss: 0.41448975 dnn loss: 0.9938708543777466 p loss: 0.005354396067559719\n",
            "loss: 1.3485417 recon loss: 0.41785067 dnn loss: 0.9259812235832214 p loss: 0.004709818214178085\n",
            "loss: 1.2603012 recon loss: 0.438722 dnn loss: 0.8166348934173584 p loss: 0.004944360628724098\n",
            "e: 3\n",
            "loss: 1.1641841 recon loss: 0.41509292 dnn loss: 0.7443272471427917 p loss: 0.004763909429311752\n",
            "loss: 1.0201956 recon loss: 0.37736627 dnn loss: 0.637931227684021 p loss: 0.004898014850914478\n",
            "loss: 0.97353673 recon loss: 0.34170708 dnn loss: 0.6273310780525208 p loss: 0.00449860543012619\n",
            "loss: 0.870337 recon loss: 0.3431589 dnn loss: 0.5225145220756531 p loss: 0.004663610737770795\n",
            "e: 4\n",
            "loss: 0.59703827 recon loss: 0.34444186 dnn loss: 0.24817831814289093 p loss: 0.00441806735470891\n",
            "loss: 0.5302901 recon loss: 0.33670226 dnn loss: 0.18830612301826477 p loss: 0.005281726084649563\n",
            "loss: 0.47371852 recon loss: 0.32627922 dnn loss: 0.14253465831279755 p loss: 0.004904641583561897\n",
            "loss: 0.4810629 recon loss: 0.33948663 dnn loss: 0.13631953299045563 p loss: 0.005256711132824421\n",
            "e: 5\n",
            "loss: 0.452828 recon loss: 0.32777995 dnn loss: 0.11969427019357681 p loss: 0.00535377524793148\n",
            "loss: 0.43919903 recon loss: 0.32258764 dnn loss: 0.11101862788200378 p loss: 0.005592755600810051\n",
            "loss: 0.4290478 recon loss: 0.3202737 dnn loss: 0.1032833531498909 p loss: 0.005490739457309246\n",
            "loss: 0.42369515 recon loss: 0.31903544 dnn loss: 0.09934521466493607 p loss: 0.005314512178301811\n",
            "e: 6\n",
            "loss: 0.41502744 recon loss: 0.31039912 dnn loss: 0.09901991486549377 p loss: 0.005608414113521576\n",
            "loss: 0.4062369 recon loss: 0.3090216 dnn loss: 0.09149011969566345 p loss: 0.005725179612636566\n",
            "loss: 0.39814663 recon loss: 0.30401754 dnn loss: 0.0881333202123642 p loss: 0.005995759181678295\n",
            "loss: 0.38974276 recon loss: 0.30254185 dnn loss: 0.08159398287534714 p loss: 0.005606932751834393\n",
            "e: 7\n",
            "loss: 0.38345546 recon loss: 0.29321522 dnn loss: 0.08485505729913712 p loss: 0.00538517665117979\n",
            "loss: 0.38181573 recon loss: 0.29188013 dnn loss: 0.08438597619533539 p loss: 0.005549617856740951\n",
            "loss: 0.38134298 recon loss: 0.293916 dnn loss: 0.08217617124319077 p loss: 0.005250811949372291\n",
            "loss: 0.38327783 recon loss: 0.29462743 dnn loss: 0.08304192125797272 p loss: 0.005608503520488739\n",
            "e: 8\n",
            "loss: 0.36814412 recon loss: 0.28380418 dnn loss: 0.07852504402399063 p loss: 0.00581490732729435\n",
            "loss: 0.37874413 recon loss: 0.2903406 dnn loss: 0.08246828615665436 p loss: 0.005935242399573326\n",
            "loss: 0.35890865 recon loss: 0.28089595 dnn loss: 0.0725022628903389 p loss: 0.005510443076491356\n",
            "loss: 0.37445492 recon loss: 0.29493618 dnn loss: 0.07393621653318405 p loss: 0.0055825006216764445\n",
            "e: 9\n",
            "loss: 0.3648512 recon loss: 0.28552783 dnn loss: 0.07360194623470306 p loss: 0.005721422284841537\n",
            "loss: 0.3615326 recon loss: 0.28672826 dnn loss: 0.06896469742059708 p loss: 0.005839642882347107\n",
            "loss: 0.34720287 recon loss: 0.27437383 dnn loss: 0.0673716738820076 p loss: 0.005457362718880176\n",
            "loss: 0.35768768 recon loss: 0.28460872 dnn loss: 0.06738273054361343 p loss: 0.005696245282888412\n",
            "e: 10\n",
            "loss: 0.35190937 recon loss: 0.27792186 dnn loss: 0.06816918402910233 p loss: 0.005818332731723786\n",
            "loss: 0.35476345 recon loss: 0.28418005 dnn loss: 0.06437073647975922 p loss: 0.006212646514177322\n",
            "loss: 0.3510086 recon loss: 0.2761057 dnn loss: 0.06914839148521423 p loss: 0.005754498392343521\n",
            "loss: 0.35384235 recon loss: 0.2815513 dnn loss: 0.06632810086011887 p loss: 0.005962929502129555\n",
            "e: 11\n",
            "loss: 0.34354827 recon loss: 0.27554113 dnn loss: 0.061985258013010025 p loss: 0.006021887809038162\n",
            "loss: 0.34460002 recon loss: 0.27317017 dnn loss: 0.06548507511615753 p loss: 0.005944801121950149\n",
            "loss: 0.34259093 recon loss: 0.27392048 dnn loss: 0.06292902678251266 p loss: 0.005741402506828308\n",
            "loss: 0.34302136 recon loss: 0.2767347 dnn loss: 0.06007229536771774 p loss: 0.006214341893792152\n",
            "e: 12\n",
            "loss: 0.33399245 recon loss: 0.27100232 dnn loss: 0.05739530548453331 p loss: 0.005594828724861145\n",
            "loss: 0.33758736 recon loss: 0.27310854 dnn loss: 0.0582558736205101 p loss: 0.0062229204922914505\n",
            "loss: 0.33617866 recon loss: 0.27186704 dnn loss: 0.058266837149858475 p loss: 0.006044773198664188\n",
            "loss: 0.34228945 recon loss: 0.27645057 dnn loss: 0.05983481928706169 p loss: 0.00600405614823103\n",
            "e: 13\n",
            "loss: 0.33208153 recon loss: 0.26962188 dnn loss: 0.05624235421419144 p loss: 0.006217295117676258\n",
            "loss: 0.33627495 recon loss: 0.2724923 dnn loss: 0.05759098380804062 p loss: 0.006191659346222877\n",
            "loss: 0.32407576 recon loss: 0.26099744 dnn loss: 0.057337686419487 p loss: 0.0057406313717365265\n",
            "loss: 0.33230865 recon loss: 0.27154875 dnn loss: 0.05447157472372055 p loss: 0.006288318894803524\n",
            "e: 14\n",
            "loss: 0.33176646 recon loss: 0.26842153 dnn loss: 0.05733400583267212 p loss: 0.00601092092692852\n",
            "loss: 0.33519968 recon loss: 0.27165323 dnn loss: 0.057297445833683014 p loss: 0.006249008327722549\n",
            "loss: 0.31694335 recon loss: 0.2560676 dnn loss: 0.05468767136335373 p loss: 0.006188058480620384\n",
            "loss: 0.32711285 recon loss: 0.26771313 dnn loss: 0.053265590220689774 p loss: 0.0061341080814599986\n",
            "e: 15\n",
            "loss: 0.32713357 recon loss: 0.26560828 dnn loss: 0.05556045100092888 p loss: 0.005964833870530128\n",
            "loss: 0.32745418 recon loss: 0.26841366 dnn loss: 0.05288384109735489 p loss: 0.006156691722571849\n",
            "loss: 0.3275693 recon loss: 0.26718426 dnn loss: 0.05462575703859329 p loss: 0.005759308487176895\n",
            "loss: 0.32719642 recon loss: 0.26549995 dnn loss: 0.05520422011613846 p loss: 0.0064922522753477095\n",
            "e: 16\n",
            "loss: 0.31889528 recon loss: 0.26107222 dnn loss: 0.05166109278798103 p loss: 0.0061619427055120465\n",
            "loss: 0.32173046 recon loss: 0.26493645 dnn loss: 0.05029996111989021 p loss: 0.006494058296084404\n",
            "loss: 0.31685573 recon loss: 0.2584443 dnn loss: 0.052213866263628006 p loss: 0.006197545677423477\n",
            "loss: 0.32632977 recon loss: 0.2700618 dnn loss: 0.05010402202606201 p loss: 0.006163965538144111\n",
            "e: 17\n",
            "loss: 0.32066926 recon loss: 0.26389438 dnn loss: 0.04993147403001785 p loss: 0.006843414902687073\n",
            "loss: 0.32508308 recon loss: 0.26613632 dnn loss: 0.05231912061572075 p loss: 0.006627645157277584\n",
            "loss: 0.31259257 recon loss: 0.25598326 dnn loss: 0.05022000893950462 p loss: 0.006389287859201431\n",
            "loss: 0.3244619 recon loss: 0.26724494 dnn loss: 0.05089779198169708 p loss: 0.006319182738661766\n",
            "e: 18\n",
            "loss: 0.30859444 recon loss: 0.25459862 dnn loss: 0.04787365347146988 p loss: 0.006122159957885742\n",
            "loss: 0.31769854 recon loss: 0.2630521 dnn loss: 0.048072267323732376 p loss: 0.006574161909520626\n",
            "loss: 0.3117451 recon loss: 0.2586581 dnn loss: 0.04717203229665756 p loss: 0.0059149604290723795\n",
            "loss: 0.32073173 recon loss: 0.26601803 dnn loss: 0.048539191484451294 p loss: 0.006174515001475811\n",
            "e: 19\n",
            "loss: 0.31339082 recon loss: 0.26025343 dnn loss: 0.046588391065597534 p loss: 0.006548991054296493\n",
            "loss: 0.32013884 recon loss: 0.26365232 dnn loss: 0.04984229803085327 p loss: 0.006644210591912269\n",
            "loss: 0.31282887 recon loss: 0.25711253 dnn loss: 0.049519769847393036 p loss: 0.006196555495262146\n",
            "loss: 0.31906646 recon loss: 0.26553893 dnn loss: 0.047501835972070694 p loss: 0.006025713309645652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_iter = iter(test_loader)\n",
        "test_img_0, test_label_0 = next(dataset_iter)\n",
        "\n",
        "test_img_1, test_label_1 = next(dataset_iter)"
      ],
      "metadata": {
        "id": "-SVaN8LyZhY_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img_0 = test_img_0.cuda()\n",
        "test_img_1 = test_img_1.cuda()\n",
        "test_label_0 = test_label_0.cuda()\n",
        "test_label_1 = test_label_1.cuda()\n",
        "\n",
        "out = model(test_img_0, test_label_0, test_label_1)\n"
      ],
      "metadata": {
        "id": "Hn1mN19IZybX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_image(test_img_0.data, './output/%03d/%04d_img.png' % ( 60, 0))\n",
        "save_image(out.data, './output/%03d/%04d_recon.png' % ( 60, 0))\n",
        "save_image(test_img_1.data, './output/%03d/%04d_recon_label.png' % (60, 0))"
      ],
      "metadata": {
        "id": "WcSD5yp5Z-jT"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}